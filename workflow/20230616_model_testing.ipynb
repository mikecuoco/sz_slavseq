{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SLAV-calling model on 7 individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs in this system: 48\n",
      "numpy: 1.23.5\n",
      "pandas: 1.5.3\n",
      "pyarrow: 10.0.1\n"
     ]
    }
   ],
   "source": [
    "# basic\n",
    "import os\n",
    "\n",
    "print(f\"Number of CPUs in this system: {os.cpu_count()}\")\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "import pyranges as pr\n",
    "\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "print(f\"pyarrow: {pyarrow.__version__}\")\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay\n",
    "from flaml import AutoML\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# custom\n",
    "from scripts.fit import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = [1, 3, 4, 5, 8, 27]\n",
    "donors = pd.read_csv(\n",
    "    \"/iblm/logglun02/mcuoco/workflows/sz_slavseq/config/all_donors.tsv\", sep=\"\\t\"\n",
    ")[\"donor_id\"].to_list()\n",
    "donors.remove(\"CommonBrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(\n",
    "    [\n",
    "        pq.read_table(f\"../results/model/labelled_windows/{d}.pqt\").to_pandas()\n",
    "        for d in donors\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subplots\n",
    "fig, axes = plt.subplots(\n",
    "    len(donors), len(anno.keys()), figsize=(4 * len(anno.keys()), 4 * len(donors))\n",
    ")\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, d in enumerate(data[\"donor_id\"].unique()):\n",
    "    for j, l in enumerate(anno.keys()):\n",
    "        ddf = data.loc[(data[\"donor_id\"] == d) & (data[l] == True), :]\n",
    "        for c in ddf[\"cell_id\"].unique():\n",
    "            sns.ecdfplot(\n",
    "                data=ddf[ddf[\"cell_id\"] == c],\n",
    "                x=\"nreads\",\n",
    "                ax=axes[i, j],\n",
    "                legend=False,\n",
    "                stat=\"count\",\n",
    "                complementary=True,\n",
    "                alpha=0.3,\n",
    "                c=sns.color_palette()[0],\n",
    "            ).set(xscale=\"log\", yscale=\"log\", title=f\"{d}: {l}\", xlabel=\"# Read 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove RMSK and blacklist classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove windows in blacklist regions\n",
    "# df = df.loc[~df[\"label\"].isin([\"blacklist\"]), :]\n",
    "# remove windows with ref reads\n",
    "df = df.loc[df[\"ref_reads\"] == 0, :]\n",
    "# fillna 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label knrgl and knrgl_1kb_3end as knrgl\n",
    "df[\"label\"] = df[\"label\"].replace({\"knrgl_1kb_3end\": \"knrgl\"})\n",
    "# label all other windows as unknown\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: \"unknown\" if x != \"knrgl\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ddf = df[df[\"donor_id\"] == \"1\"]\n",
    "\n",
    "for c in ddf[\"cell_id\"].unique():\n",
    "    sns.ecdfplot(\n",
    "        data=ddf[ddf[\"cell_id\"] == c],\n",
    "        x=\"nr1\",\n",
    "        hue=\"label\",\n",
    "        ax=axes,\n",
    "        legend=False,\n",
    "        stat=\"count\",\n",
    "        complementary=True,\n",
    "        alpha=0.3,\n",
    "    ).set(xscale=\"log\", yscale=\"log\", xlabel=\"# Read 1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "keys = [\"_q\", \"frac\", \"gini\", \"bias\"]\n",
    "for c in df.columns:\n",
    "    for k in keys:\n",
    "        if k in c:\n",
    "            features.append(c)\n",
    "\n",
    "# encode labels\n",
    "df[\"label_encoded\"] = df[\"label\"].map({\"knrgl\": 1, \"unknown\": 0})\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set flaml settings\n",
    "# NOTE: Don't try logistic regression, it's too slow, doesn't converge, and doesn't perform well\n",
    "flaml_settings = dict(\n",
    "    task=\"classification\",\n",
    "    n_jobs=16,\n",
    "    estimator_list=[\"xgboost\", \"rf\"],\n",
    "    early_stop=True,\n",
    "    skip_transform=True,  # don't preprocess data\n",
    "    auto_augment=False,  # don't augment rare classes\n",
    "    # starting_points=\"static\", # use data-independent hyperparameterstarting points\n",
    "    log_training_metric=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsk = pr.read_bed(\n",
    "    \"/iblm/netapp/data4/mcuoco/sz_slavseq/resources/rmsk_1kb_3end.bed\", as_df=True\n",
    ")\n",
    "\n",
    "# define evaluation function\n",
    "def precision_recall(pred: pd.DataFrame, knrgl: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculate precision and recall for a binary classifier\n",
    "    pred: predicted labels for genomic windows\n",
    "    insertions: L1 annotations\n",
    "    \"\"\"\n",
    "    assert \"pred\" in pred.columns, \"pred must have column 'pred'\"\n",
    "    assert set(pred.pred.unique()) == set([0, 1]), \"pred must be binary\"\n",
    "\n",
    "    for col in [\"Chromosome\", \"Start\", \"End\"]:\n",
    "        assert col in pred.columns, f\"pred must have column {col}\"\n",
    "        assert col in rmsk.columns, f\"rmsk must have column {col}\"\n",
    "        assert col in knrgl.columns, f\"knrgl must have column {col}\"\n",
    "\n",
    "    # only consider insertions that have windows\n",
    "    insertions = pr.PyRanges(insertions).overlap(pr.PyRanges(pred)).df\n",
    "\n",
    "    # how many insertions were detected?\n",
    "    y_pos = pred.loc[pred[\"pred\"] == 1, :]\n",
    "    tp = len(pr.PyRanges(insertions).overlap(pr.PyRanges(y_pos)).df)\n",
    "\n",
    "    # how many insertions were false positives?\n",
    "    fp = len(pr.PyRanges(insertions).overlap(pr.PyRanges(y_pos), invert=True).df)\n",
    "\n",
    "    # how many insertions were missed?\n",
    "    y_neg = pred.loc[pred[\"pred\"] == 0, :]\n",
    "    fn = len(pr.PyRanges(insertions).overlap(pr.PyRanges(y_neg)).df)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(tune_data, eval_data):\n",
    "\n",
    "    # get train and test chromosomes\n",
    "    assert (\n",
    "        np.intersect1d(\n",
    "            tune_data[\"Chromosome\"].unique(), eval_data[\"Chromosome\"].unique()\n",
    "        ).size\n",
    "        == 0\n",
    "    ), \"Train and test chromosomes must be mutually exclusive\"\n",
    "\n",
    "    sgkf = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "    # fit using holdout data\n",
    "    clf = AutoML()\n",
    "\n",
    "    clf.fit(\n",
    "        X_train=tune_data[features],\n",
    "        y_train=tune_data[\"label_encoded\"],\n",
    "        metric=\"f1\",\n",
    "        time_budget=600,\n",
    "        eval_method=\"cv\",\n",
    "        split_type=sgkf,\n",
    "        groups=tune_data[\"Chromosome\"],\n",
    "        log_file_name=\"flaml_cv.log\",\n",
    "        **flaml_settings\n",
    "    )\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    \"min_reads\": [],\n",
    "    \"model\": [],\n",
    "}\n",
    "for mr in [100, 200]:\n",
    "    # define data to tune on\n",
    "    eval_chr = \"chr1\"\n",
    "    eval_data = df.loc[\n",
    "        (df[\"Chromosome\"] == eval_chr) & (df[\"nr1\"] >= mr), :\n",
    "    ].reset_index()\n",
    "    tune_data = df.loc[\n",
    "        (df[\"Chromosome\"] != eval_chr) & (df[\"nr1\"] >= mr), :\n",
    "    ].reset_index()\n",
    "    clf = train_model(tune_data, eval_data)\n",
    "    res[\"min_reads\"].append(mr)\n",
    "    res[\"model\"].append(clf)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.automl.data import get_output_from_log\n",
    "\n",
    "time, best_valid_loss, valid_loss, config, metric = get_output_from_log(\n",
    "    \"flaml_cv.log\", time_budget=600\n",
    ")\n",
    "plot_df = pd.DataFrame(\n",
    "    {\n",
    "        \"time\": time,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_loss\": [m[\"train_loss\"] for m in metric],\n",
    "    }\n",
    ")\n",
    "plot_df = plot_df.melt(id_vars=\"time\", var_name=\"metric\", value_name=\"loss\")\n",
    "sns.scatterplot(data=plot_df, x=\"time\", y=\"loss\", hue=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for mr, clf in zip(res[\"min_reads\"], res[\"model\"]):\n",
    "    eval_chr = \"chr1\"\n",
    "    eval_data = df.loc[\n",
    "        (df[\"Chromosome\"] == eval_chr) & (df[\"nr1\"] >= mr), :\n",
    "    ].reset_index()\n",
    "    PrecisionRecallDisplay.from_estimator(\n",
    "        clf,\n",
    "        eval_data[features],\n",
    "        eval_data[\"label_encoded\"],\n",
    "        name=f\"min reads: {mr}\",\n",
    "        ax=ax[0],\n",
    "    )\n",
    "    RocCurveDisplay.from_estimator(\n",
    "        clf,\n",
    "        eval_data[features],\n",
    "        eval_data[\"label_encoded\"],\n",
    "        name=f\"min reads: {mr}\",\n",
    "        ax=ax[1],\n",
    "    )\n",
    "\n",
    "# remove legend from first ax\n",
    "\n",
    "# save as png\n",
    "# fig.savefig(\"flaml_holdout.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"nr1\"] > res[\"min_reads\"][-1]][\"pred\"] = res[\"model\"][-1].predict(\n",
    "    df[df[\"nr1\"] > res[\"min_reads\"][-1]][features]\n",
    ")\n",
    "calls = df[\n",
    "    (df[\"nr1\"] > res[\"min_reads\"][-1]) & (df[\"pred\"] == 1) & (df[\"label\"] == \"unknown\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\n",
    "    \"/iblm/logglun02/mcuoco/workflows/sz_slavseq/config/7donor_donors.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index_col=0,\n",
    ")\n",
    "meta[\"calls\"] = calls.groupby(\"donor_id\").size()\n",
    "meta[[\"sex\", \"age\", \"race\", \"diagnosis\", \"calls\"]].sort_values(\"calls\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
