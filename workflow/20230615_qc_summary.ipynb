{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pysam\n",
    "from myutils.rmsk import read_rmsk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing depth before/after trimming and filtering\n",
    "\n",
    "(parsing cutadapt logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"/iblm/logglun02/mcuoco/workflows/sz_slavseq/results/fastq\")\n",
    "\n",
    "res = defaultdict(dict)\n",
    "for f in p.rglob(\"*/*qc.txt\"):\n",
    "    # skip bulk gDNA samples\n",
    "    if (\"gDNA\" in f.name) or (\"CommonBrain\" in f.parent.name):\n",
    "        continue\n",
    "    sample = f.name.split(\".\")[0]\n",
    "    stage = f.name.split(\".\")[1]\n",
    "    lines = f.read_text().splitlines()\n",
    "    res[sample][\"donor_id\"] = f.parent.name\n",
    "    total_line = [l for l in lines if \"Total read pairs\" in l][0]\n",
    "    if stage == \"trimmed\":\n",
    "        res[sample][\"Raw\"] = int(total_line.split()[-1].replace(\",\", \"\"))\n",
    "    elif stage == \"filtered\":\n",
    "        res[sample][\"After trimming\"] = int(total_line.split()[-1].replace(\",\", \"\"))\n",
    "        pairs_written_line = [l for l in lines if \"Pairs written\" in l][0]\n",
    "        res[sample][\"After filtering\"] = int(\n",
    "            pairs_written_line.split()[4].replace(\",\", \"\")\n",
    "        )\n",
    "\n",
    "res = pd.DataFrame(res).T\n",
    "# res[\"pct_after_trimming\"] = res[\"after_trimming\"] / res[\"total_pairs\"]\n",
    "# res[\"pct_after_filtering\"] = res[\"after_filtering\"] / res[\"total_pairs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.histplot(\n",
    "    data=res.melt(id_vars=\"donor_id\"), x=\"value\", hue=\"variable\", element=\"step\"\n",
    ")\n",
    "g.set(xlabel=\"# Read pairs\", ylabel=\"# Cells\")\n",
    "g.legend_.set_title(None)\n",
    "sns.despine()\n",
    "\n",
    "# rename color values\n",
    "for t, l in zip(g.legend_.texts, [\"Raw\", \"After trimming\", \"After filtering\"]):\n",
    "    m = res[l].mean()\n",
    "    t.set_text(f\"{l} (mean: {m/1e6:.1f}e6)\")\n",
    "\n",
    "# save as svg\n",
    "plt.savefig(\"npairs_after_trimming.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove legend title\n",
    "g = sns.ecdfplot(data=res.melt(id_vars=\"donor_id\"), x=\"value\", hue=\"variable\")\n",
    "g.set(xlabel=\"# Read pairs\")\n",
    "g.legend_.set_title(None)\n",
    "sns.despine()\n",
    "\n",
    "# rename color values\n",
    "for t, l in zip(g.legend_.texts, [\"Raw\", \"After trimming\", \"After filtering\"]):\n",
    "    m = res[l].mean()\n",
    "    t.set_text(f\"{l} (mean: {m/1e6:.1f}e6)\")\n",
    "\n",
    "# add dotted line at 1M reads\n",
    "plt.axvline(1e6, ls=\"--\", color=\"black\")\n",
    "\n",
    "# save as svg\n",
    "plt.savefig(\"npairs_after_trimming.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read length after trimming\n",
    "\n",
    "Parsing fastqc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metadata\n",
    "metadata = pd.read_csv(\n",
    "    \"/iblm/logglun02/mcuoco/workflows/sz_slavseq/config/slavseq_metadata.tsv\", sep=\"\\t\"\n",
    ")\n",
    "metadata[\"TISSUE_ID\"] = metadata[\"TISSUE_ID\"].str.replace(\"D0\", \"D\")\n",
    "metadata[\"TISSUE_ID\"] = metadata[\"TISSUE_ID\"].str.replace(\"H0\", \"H\")\n",
    "metadata = (\n",
    "    metadata[[\"TISSUE_ID\", \"SEQUENCING\"]].set_index(\"TISSUE_ID\")[\"SEQUENCING\"].to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"/iblm/logglun02/mcuoco/workflows/sz_slavseq/results/qc/fastqc\")\n",
    "\n",
    "res = []\n",
    "for f in p.rglob(\"*/*fastqc.zip\"):\n",
    "    # skip bulk gDNA samples\n",
    "    if (\"gDNA\" in f.name) or (\"CommonBrain\" in f.parent.name):\n",
    "        continue\n",
    "    sample = f.name.split(\".\")[0].rstrip(\"_R[12]\")\n",
    "    donor = f.parent.name\n",
    "    read = f.name.split(\".\")[0][-2::]\n",
    "    stage = f.name.split(\".\")[1]\n",
    "    tissue_id = \"USH\" if \"USH\" in sample.upper() else \"USD\"\n",
    "    instrument = metadata[tissue_id + donor]\n",
    "\n",
    "    # get length distribution\n",
    "    with ZipFile(f) as z:\n",
    "        target = [i for i in z.namelist() if \"fastqc_data.txt\" in i][0]\n",
    "        m = z.read(target).decode(\"utf-8\")\n",
    "    sqlen_ind = m.find(\">>Sequence Length Distribution\")\n",
    "    endmod_ind = m[sqlen_ind:].find(\">>END_MODULE\")\n",
    "    lines = m[sqlen_ind:][:endmod_ind].splitlines()[1:]\n",
    "    lines = [l.split(\"\\t\") for l in lines]\n",
    "\n",
    "    # save to DataFrame\n",
    "    df = pd.DataFrame(lines, columns=[\"length\", \"count\"])[1:].copy()\n",
    "    df[\"length\"] = df[\"length\"].apply(lambda x: x.split(\"-\")[0]).astype(int)\n",
    "    df[\"count\"] = df[\"count\"].apply(lambda x: x.split(\".\")[0]).astype(int)\n",
    "    df.set_index(\"length\", inplace=True)\n",
    "    df[\"stage\"] = stage\n",
    "    df[\"read\"] = read\n",
    "    df[\"instrument\"] = instrument\n",
    "    df[\"sample\"] = sample\n",
    "    res.append(df)\n",
    "\n",
    "\n",
    "res = pd.concat(res)\n",
    "\n",
    "sample_lengths = (\n",
    "    res[res[\"stage\"] == \"raw\"]\n",
    "    .reset_index()[[\"length\", \"sample\"]]\n",
    "    .groupby([\"sample\"])\n",
    "    .mean()[\"length\"]\n",
    "    .to_dict()\n",
    ")\n",
    "res[\"raw_length\"] = res[\"sample\"].map(sample_lengths).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    res[res[\"stage\"] == \"trimmed\"],\n",
    "    kind=\"line\",\n",
    "    x=\"length\",\n",
    "    y=\"count\",\n",
    "    hue=\"raw_length\",\n",
    "    col=\"read\",\n",
    "    col_order=[\"R1\", \"R2\"],\n",
    "    palette=\"Set1\",\n",
    ").set(\n",
    "    xlabel=\"Read length after trimming (bp)\",\n",
    "    ylabel=\"# Reads\",\n",
    ")\n",
    "\n",
    "# rename columns\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Read 1\")\n",
    "axes[1].set_title(\"Read 2\")\n",
    "\n",
    "# move legend above plot\n",
    "sns.move_legend(g, \"upper center\", bbox_to_anchor=(0.5, 1.1), ncol=3)\n",
    "\n",
    "# set legend title\n",
    "g._legend.set_title(\"Raw read length (bp)\")\n",
    "\n",
    "# save as svg\n",
    "plt.savefig(\"trimmed_read_length.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(dict)\n",
    "for f in Path(\"/iblm/logglun02/mcuoco/workflows/sz_slavseq/results/qc/flagstat\").rglob(\n",
    "    \"*/*.genome.flagstat\"\n",
    "):\n",
    "    donor = f.parent.name\n",
    "    sample = f.name.split(\".\")[0]\n",
    "    lines = f.read_text().splitlines()\n",
    "    if int(lines[0].split()[0]) < 1e6:\n",
    "        continue\n",
    "    res[sample][\"donor_id\"] = donor\n",
    "    res[sample][\"Primary mapped\"] = int(lines[7].split()[0])\n",
    "    res[sample][\"Primary mapped non-duplicated\"] = int(lines[7].split()[0]) - int(\n",
    "        lines[5].split()[0]\n",
    "    )\n",
    "\n",
    "res = pd.DataFrame(res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.histplot(data=res.melt(id_vars=\"donor_id\"), x=\"value\", hue=\"variable\")\n",
    "g.set(xlabel=\"# Alignments\", ylabel=\"# Cells\")\n",
    "g.legend_.set_title(None)\n",
    "sns.despine()\n",
    "\n",
    "# rename color values\n",
    "for t, l in zip(g.legend_.texts, [\"Primary mapped\", \"Primary mapped non-duplicated\"]):\n",
    "    m = res[l].mean()\n",
    "    t.set_text(f\"{l} (mean: {m/1e6:.1f}e6)\")\n",
    "\n",
    "# save as svg\n",
    "plt.savefig(\"nalignments.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove legend title\n",
    "g = sns.ecdfplot(data=res.melt(id_vars=\"donor_id\"), x=\"value\", hue=\"variable\")\n",
    "g.set(xlabel=\"# Alignments\", xscale=\"log\")\n",
    "g.legend_.set_title(None)\n",
    "sns.despine()\n",
    "\n",
    "# # rename color values\n",
    "# for t, l in zip(g.legend_.texts, [\"Raw\", \"After trimming\", \"After filtering\"]):\n",
    "#     m = res[l].mean()\n",
    "#     t.set_text(f\"{l} (mean: {m/1e6:.1f}M)\")\n",
    "\n",
    "# # add dotted line at 1M reads\n",
    "# plt.axvline(1e6, ls=\"--\", color=\"black\")\n",
    "# plt.figure(figsize=(10, 10))\n",
    "\n",
    "# # save as svg\n",
    "# plt.savefig(\"npairs_after_trimming.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsk = read_rmsk(\n",
    "    \"https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.out.gz\"\n",
    ")\n",
    "# get L1HS coordinates\n",
    "l1hs = rmsk[rmsk[\"repName\"].isin([\"L1HS\", \"L1PA2\", \"L1PA3\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"/iblm/logglun02/mcuoco/workflows/sz_slavseq/results\"\n",
    "samples = pd.read_csv(\n",
    "    \"/iblm/logglun02/mcuoco/workflows/sz_slavseq/config/7donor_samples.tsv\", sep=\"\\t\"\n",
    ")\n",
    "\n",
    "donors = [\"CommonBrain\", 1, 3, 4, 5, 8, 27]\n",
    "res = defaultdict()\n",
    "for d in donors:\n",
    "    donor_samples = samples[samples[\"donor_id\"] == str(d)][\"sample_id\"].tolist()\n",
    "    for s in tqdm(donor_samples):\n",
    "        # get sample total reads\n",
    "        total_aln = int(\n",
    "            pysam.view(f\"{p}/align/{d}/{s}.tagged.sorted.bam\", \"-c\").rstrip()\n",
    "        )\n",
    "        rmsk1 = pd.read_csv(\n",
    "            f\"{p}/qc/l1_coverage/{d}/{s}.rmsk.r1.bed\",\n",
    "            sep=\"\\t\",\n",
    "            header=None,\n",
    "            usecols=[0, 1, 2, 3, 6],\n",
    "            names=[\"Chromosome\", \"Start\", \"End\", \"label\", \"coverage\"],\n",
    "        ).set_index([\"Chromosome\", \"Start\", \"End\", \"label\"])\n",
    "        rmsk2 = pd.read_csv(\n",
    "            f\"{p}/qc/l1_coverage/{d}/{s}.rmsk.r2.bed\",\n",
    "            sep=\"\\t\",\n",
    "            header=None,\n",
    "            usecols=[0, 1, 2, 3, 6],\n",
    "            names=[\"Chromosome\", \"Start\", \"End\", \"label\", \"coverage\"],\n",
    "        ).set_index([\"Chromosome\", \"Start\", \"End\", \"label\"])\n",
    "        rmsk = pd.concat([rmsk1, rmsk2], axis=1).sum(axis=1)\n",
    "        knrgl1 = pd.read_csv(\n",
    "            f\"{p}/qc/l1_coverage/{d}/{s}.knrgl.r1.bed\",\n",
    "            sep=\"\\t\",\n",
    "            header=None,\n",
    "            usecols=[0, 1, 2, 44],\n",
    "            names=[\"Chromosome\", \"Start\", \"End\", \"coverage\"],\n",
    "        )\n",
    "        knrgl1[\"label\"] = \"KNRGL\"\n",
    "        knrgl1.set_index([\"Chromosome\", \"Start\", \"End\", \"label\"], inplace=True)\n",
    "        knrgl2 = pd.read_csv(\n",
    "            f\"{p}/qc/l1_coverage/{d}/{s}.knrgl.r1.bed\",\n",
    "            sep=\"\\t\",\n",
    "            header=None,\n",
    "            usecols=[0, 1, 2, 44],\n",
    "            names=[\"Chromosome\", \"Start\", \"End\", \"coverage\"],\n",
    "        )\n",
    "        knrgl2[\"label\"] = \"KNRGL\"\n",
    "        knrgl2.set_index([\"Chromosome\", \"Start\", \"End\", \"label\"], inplace=True)\n",
    "        knrgl = pd.concat([knrgl1, knrgl2], axis=1).sum(axis=1)\n",
    "        comb = pd.concat([rmsk, knrgl], axis=0)\n",
    "        res[s] = comb / (total_aln / 1e6)  # convert to RPM\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.DataFrame(res)\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"level_0\": \"sample_id\",\n",
    "            \"level_1\": \"Chromosome\",\n",
    "            \"level_2\": \"Start\",\n",
    "            \"level_3\": \"End\",\n",
    "            \"level_4\": \"label\",\n",
    "            0: \"coverage\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "# keep primary assembly\n",
    "df = df[df[\"Chromosome\"].isin([f\"chr{i}\" for i in range(1, 22)] + [\"chrX\", \"chrY\"])]\n",
    "df[\"chr_num\"] = df[\"Chromosome\"].str.extract(\"chr(.*)\")\n",
    "df[\"chr_num\"] = df[\"chr_num\"].apply(\n",
    "    lambda x: 23 if x == \"X\" else (24 if x == \"Y\" else int(x))\n",
    ")\n",
    "df.sort_values([\"chr_num\", \"Start\"], inplace=True)\n",
    "df[\"ind\"] = range(len(df))\n",
    "\n",
    "# melt dataframe\n",
    "plot_df = df.melt(\n",
    "    id_vars=[\"Chromosome\", \"Start\", \"End\", \"label\", \"ind\"],\n",
    "    value_name=\"RPM\",\n",
    "    var_name=\"sample_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "\n",
    "plot_df = plot_df[plot_df[\"Chromosome\"] == \"chr1\"]\n",
    "sns.despine()\n",
    "g1 = sns.lineplot(\n",
    "    data=plot_df[plot_df[\"label\"] == \"L1HS\"],\n",
    "    x=\"Start\",\n",
    "    y=\"RPM\",\n",
    "    ax=axs[0],\n",
    "    errorbar=\"sd\",\n",
    ")\n",
    "g1.set(title=\"L1HS\")\n",
    "g1.set(xlabel=\"Chromosome 1\", ylabel=\"reads-per-million\")\n",
    "\n",
    "sns.despine()\n",
    "g2 = sns.lineplot(\n",
    "    data=plot_df[plot_df[\"label\"] == \"L1PA2\"],\n",
    "    x=\"Start\",\n",
    "    y=\"RPM\",\n",
    "    ax=axs[1],\n",
    "    errorbar=\"sd\",\n",
    ")\n",
    "g2.set(title=\"L1PA2\")\n",
    "g2.set(xlabel=\"Chromosome 1\", ylabel=\"reads-per-million\")\n",
    "\n",
    "# save to svg\n",
    "plt.savefig(\"l1hs_l1pa2_chr1_commonbrain.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [\"L1HS\", \"L1PA2\"]:\n",
    "    g = sns.clustermap(\n",
    "        df[df[\"label\"] == label]\n",
    "        .set_index([\"Chromosome\", \"Start\", \"End\", \"label\", \"chr_num\", \"ind\"])\n",
    "        .transform(\"log2\")\n",
    "        .corr(\"pearson\"),\n",
    "    )\n",
    "\n",
    "    # remove row and col labels\n",
    "    g.ax_heatmap.set_xticklabels([])\n",
    "    g.ax_heatmap.set_xticks([])\n",
    "    g.ax_heatmap.set_yticklabels([])\n",
    "    g.ax_heatmap.set_yticks([])\n",
    "\n",
    "    # hide dendrogram\n",
    "    g.ax_row_dendrogram.set_visible(False)\n",
    "    g.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "    # add title\n",
    "    g.ax_heatmap.set_title(label)\n",
    "\n",
    "    # add legend title\n",
    "    g.cax.set_title(\"Pearson correlation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get KNRGL and window files for each donor\n",
    "donors = [\"CommonBrain\", 1, 3, 4, 5, 8, 27]\n",
    "# donors = [\"CommonBrain\"]\n",
    "donor_files = {}\n",
    "for d in donors:\n",
    "    donor_files[d] = defaultdict(list)\n",
    "    p = Path(f\"/iblm/netapp/data4/mcuoco/sz_slavseq/results/qc/l1_coverage/{d}\")\n",
    "    for r, a in product([\"r1\", \"r2\"], [\"xtea\", \"rmsk\"]):\n",
    "        for f in p.rglob(f\"*{a}.{r}.bed\"):\n",
    "            donor_files[d][f\"{a}_{r}\"].append(str(f))\n",
    "        for f in p.rglob(f\"*{a}_1kb_3end.{r}.txt\"):\n",
    "            donor_files[d][f\"{a}_1kb_3end_{r}\"].append(str(f))\n",
    "        for f in p.rglob(f\"*{a}_20kb.{r}.txt\"):\n",
    "            donor_files[d][f\"{a}_20kb_{r}\"].append(str(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for a single donor\n",
    "fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(18, 3), sharex=True)\n",
    "\n",
    "# subfams = [\"KNRGL\", \"L1HS\", \"L1PA2\", \"L1PA3\", \"L1PA4\", \"L1PA5\"]\n",
    "subfams = [\"KNRGL\", \"L1HS\", \"L1PA2\", \"L1PA3\", \"L1PA4\", \"L1PA5\"]\n",
    "\n",
    "for r, k in zip(donor_files[1][\"rmsk_1kb_3end_r1\"], donor_files[1][\"xtea_1kb_3end_r1\"]):\n",
    "    df = pd.read_csv(\n",
    "        k, sep=\"\\t\", header=None, usecols=[3, 6], names=[\"label\", \"coverage\"]\n",
    "    )\n",
    "    knrgl = pd.read_csv(k, sep=\"\\t\", header=None, usecols=[6], names=[\"coverage\"])\n",
    "    knrgl[\"label\"] = \"KNRGL\"\n",
    "    df = pd.concat([knrgl, rmsk])\n",
    "    df[\"coverage\"] += 1\n",
    "    for j, l in enumerate(subfams):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            sns.ecdfplot(\n",
    "                data=df[df.label == l],\n",
    "                x=\"coverage\",\n",
    "                stat=\"count\",\n",
    "                alpha=0.3,\n",
    "                color=sns.color_palette()[0],\n",
    "                complementary=True,\n",
    "                hue=None,\n",
    "                ax=axes[j],\n",
    "            ).set(xscale=\"log\", ylabel=\"\", xlabel=\"\", xlim=(1, 4000))\n",
    "            sns.despine()\n",
    "\n",
    "for ax, col in zip(axes, subfams):\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(\"Read 1 Coverage\")\n",
    "    ax.set_ylabel(\"# Loci\", rotation=90, size=\"large\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# add space on left\n",
    "fig.subplots_adjust(left=0.1)\n",
    "\n",
    "# save as svg\n",
    "# plt.savefig(\"l1_coverage_commonbrain.svg\", bbox_inches=\"tight\")\n",
    "# save as png\n",
    "# plt.savefig(\"l1_coverage_commonbrain.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
