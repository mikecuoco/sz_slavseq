{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False positive analysis\n",
    "\n",
    "Where are the false positives? How are they distributed?\n",
    "\n",
    "TODO:\n",
    "1. Analze poorly performing tissue in addition to CommonBrain (a good performer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CommonBrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1804055 entries, 61 to 19956329\n",
      "Columns: 117 entries, Chromosome to neg_score_mean\n",
      "dtypes: bool(21), float16(82), float64(1), int32(7), int64(2), int8(1), object(3)\n",
      "memory usage: 464.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "# read and save data, takes a long time to run\n",
    "data = pq.read_table(\n",
    "    \"../results/model/get_labels/CommonBrain_nonrefonly.pqt\"\n",
    ").to_pandas()\n",
    "data = data.loc[data.rpm >= 2, :]\n",
    "\n",
    "# convert float32 to float16\n",
    "for c in data.columns:\n",
    "    if (data[c].dtype == \"float32\") and (c != \"rpm\"):\n",
    "        data[c] = data[c].astype(\"float16\")\n",
    "        assert not np.isinf(data[c]).any(), f\"{c} column contains inf values\"\n",
    "        assert not data[c].isna().any(), f\"{c} column contains nan values\"\n",
    "\n",
    "# check that no rows have been duplicated\n",
    "assert (\n",
    "    data.shape[0]\n",
    "    == data[[\"Chromosome\", \"Start\", \"End\", \"cell_id\"]].drop_duplicates().shape[0]\n",
    "), \"some rows have been duplicated during labeling!\"\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>n_fwd</th>\n",
       "      <th>n_rev</th>\n",
       "      <th>n_proper_pairs</th>\n",
       "      <th>n_ref_reads</th>\n",
       "      <th>3end_gini</th>\n",
       "      <th>5end_gini</th>\n",
       "      <th>max_mapq</th>\n",
       "      <th>n_reads</th>\n",
       "      <th>rpm</th>\n",
       "      <th>orientation_bias</th>\n",
       "      <th>frac_proper_pairs</th>\n",
       "      <th>alignment_score_q0</th>\n",
       "      <th>alignment_score_q0.25</th>\n",
       "      <th>alignment_score_q0.5</th>\n",
       "      <th>alignment_score_q0.75</th>\n",
       "      <th>alignment_score_q1</th>\n",
       "      <th>alignment_score_mean</th>\n",
       "      <th>alignment_score_normed_q0</th>\n",
       "      <th>alignment_score_normed_q0.25</th>\n",
       "      <th>alignment_score_normed_q0.5</th>\n",
       "      <th>alignment_score_normed_q0.75</th>\n",
       "      <th>alignment_score_normed_q1</th>\n",
       "      <th>alignment_score_normed_mean</th>\n",
       "      <th>L1_alignment_score_q0</th>\n",
       "      <th>L1_alignment_score_q0.25</th>\n",
       "      <th>L1_alignment_score_q0.5</th>\n",
       "      <th>L1_alignment_score_q0.75</th>\n",
       "      <th>L1_alignment_score_q1</th>\n",
       "      <th>L1_alignment_score_mean</th>\n",
       "      <th>L1_alignment_score_normed_q0</th>\n",
       "      <th>L1_alignment_score_normed_q0.25</th>\n",
       "      <th>L1_alignment_score_normed_q0.5</th>\n",
       "      <th>L1_alignment_score_normed_q0.75</th>\n",
       "      <th>L1_alignment_score_normed_q1</th>\n",
       "      <th>L1_alignment_score_normed_mean</th>\n",
       "      <th>L1_reference_start_q0</th>\n",
       "      <th>L1_reference_start_q0.25</th>\n",
       "      <th>L1_reference_start_q0.5</th>\n",
       "      <th>L1_reference_start_q0.75</th>\n",
       "      <th>L1_reference_start_q1</th>\n",
       "      <th>L1_reference_start_mean</th>\n",
       "      <th>L1_reference_end_q0</th>\n",
       "      <th>L1_reference_end_q0.25</th>\n",
       "      <th>L1_reference_end_q0.5</th>\n",
       "      <th>L1_reference_end_q0.75</th>\n",
       "      <th>L1_reference_end_q1</th>\n",
       "      <th>L1_reference_end_mean</th>\n",
       "      <th>L1_Acount_q0</th>\n",
       "      <th>L1_Acount_q0.25</th>\n",
       "      <th>L1_Acount_q0.5</th>\n",
       "      <th>L1_Acount_q0.75</th>\n",
       "      <th>L1_Acount_q1</th>\n",
       "      <th>L1_Acount_mean</th>\n",
       "      <th>mate_alignment_score_q0</th>\n",
       "      <th>mate_alignment_score_q0.25</th>\n",
       "      <th>mate_alignment_score_q0.5</th>\n",
       "      <th>mate_alignment_score_q0.75</th>\n",
       "      <th>mate_alignment_score_q1</th>\n",
       "      <th>mate_alignment_score_mean</th>\n",
       "      <th>mate_alignment_score_normed_q0</th>\n",
       "      <th>mate_alignment_score_normed_q0.25</th>\n",
       "      <th>mate_alignment_score_normed_q0.5</th>\n",
       "      <th>mate_alignment_score_normed_q0.75</th>\n",
       "      <th>mate_alignment_score_normed_q1</th>\n",
       "      <th>mate_alignment_score_normed_mean</th>\n",
       "      <th>mate_read_length_q0</th>\n",
       "      <th>mate_read_length_q0.25</th>\n",
       "      <th>mate_read_length_q0.5</th>\n",
       "      <th>mate_read_length_q0.75</th>\n",
       "      <th>mate_read_length_q1</th>\n",
       "      <th>mate_read_length_mean</th>\n",
       "      <th>num_supp_alignments_q0</th>\n",
       "      <th>num_supp_alignments_q0.25</th>\n",
       "      <th>num_supp_alignments_q0.5</th>\n",
       "      <th>num_supp_alignments_q0.75</th>\n",
       "      <th>num_supp_alignments_q1</th>\n",
       "      <th>num_supp_alignments_mean</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>xtea_id</th>\n",
       "      <th>xtea</th>\n",
       "      <th>xtea_1kb_3end_id</th>\n",
       "      <th>xtea_1kb_3end</th>\n",
       "      <th>xtea_20kb</th>\n",
       "      <th>L1HS</th>\n",
       "      <th>L1HS_1kb_3end</th>\n",
       "      <th>L1HS_20kb</th>\n",
       "      <th>L1PA2</th>\n",
       "      <th>L1PA2_1kb_3end</th>\n",
       "      <th>L1PA2_20kb</th>\n",
       "      <th>L1PA3</th>\n",
       "      <th>L1PA3_1kb_3end</th>\n",
       "      <th>L1PA3_20kb</th>\n",
       "      <th>L1PA4</th>\n",
       "      <th>L1PA4_1kb_3end</th>\n",
       "      <th>L1PA4_20kb</th>\n",
       "      <th>L1PA5</th>\n",
       "      <th>L1PA5_1kb_3end</th>\n",
       "      <th>L1PA5_20kb</th>\n",
       "      <th>L1PA6</th>\n",
       "      <th>L1PA6_1kb_3end</th>\n",
       "      <th>L1PA6_20kb</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>pos_score_q0</th>\n",
       "      <th>pos_score_q0.25</th>\n",
       "      <th>pos_score_q0.5</th>\n",
       "      <th>pos_score_q0.75</th>\n",
       "      <th>pos_score_q1</th>\n",
       "      <th>pos_score_mean</th>\n",
       "      <th>neg_score_q0</th>\n",
       "      <th>neg_score_q0.25</th>\n",
       "      <th>neg_score_q0.5</th>\n",
       "      <th>neg_score_q0.75</th>\n",
       "      <th>neg_score_q1</th>\n",
       "      <th>neg_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1568750</td>\n",
       "      <td>1569500</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>2.237463</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>137.25</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>137.2500</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.75</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.25</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.395752</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>0.398926</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.25</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.2500</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.75</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.7500</td>\n",
       "      <td>0.576172</td>\n",
       "      <td>0.581055</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.581055</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>plate1_D3_S18</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CommonBrain</td>\n",
       "      <td>-28.390625</td>\n",
       "      <td>-13.484375</td>\n",
       "      <td>-9.273438</td>\n",
       "      <td>-5.898438</td>\n",
       "      <td>7.179688</td>\n",
       "      <td>-10.109375</td>\n",
       "      <td>-29.203125</td>\n",
       "      <td>-13.476562</td>\n",
       "      <td>-8.796875</td>\n",
       "      <td>-4.843750</td>\n",
       "      <td>7.929688</td>\n",
       "      <td>-9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1569000</td>\n",
       "      <td>1569750</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2.796829</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>139.7500</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>0.993164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925781</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.40625</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.410645</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>76.6250</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.0000</td>\n",
       "      <td>0.576172</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.622559</td>\n",
       "      <td>0.589355</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>plate1_D3_S18</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CommonBrain</td>\n",
       "      <td>-28.390625</td>\n",
       "      <td>-13.609375</td>\n",
       "      <td>-9.062500</td>\n",
       "      <td>-5.261719</td>\n",
       "      <td>7.179688</td>\n",
       "      <td>-9.929688</td>\n",
       "      <td>-29.203125</td>\n",
       "      <td>-13.726562</td>\n",
       "      <td>-8.812500</td>\n",
       "      <td>-5.054688</td>\n",
       "      <td>7.929688</td>\n",
       "      <td>-9.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1569250</td>\n",
       "      <td>1570000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>2.237463</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.75</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>150.7500</td>\n",
       "      <td>0.993164</td>\n",
       "      <td>0.998535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998535</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.75</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.50</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.25000</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.395752</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.410645</td>\n",
       "      <td>0.398926</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.50</td>\n",
       "      <td>78.0</td>\n",
       "      <td>76.5000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.5000</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.592773</td>\n",
       "      <td>0.622559</td>\n",
       "      <td>0.592773</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>plate1_D3_S18</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CommonBrain</td>\n",
       "      <td>-28.390625</td>\n",
       "      <td>-14.296875</td>\n",
       "      <td>-8.742188</td>\n",
       "      <td>-4.417969</td>\n",
       "      <td>9.867188</td>\n",
       "      <td>-9.421875</td>\n",
       "      <td>-29.203125</td>\n",
       "      <td>-14.492188</td>\n",
       "      <td>-8.929688</td>\n",
       "      <td>-5.128906</td>\n",
       "      <td>7.914062</td>\n",
       "      <td>-10.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1770000</td>\n",
       "      <td>1770750</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>2.400610</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>146.0</td>\n",
       "      <td>149.75</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>149.7500</td>\n",
       "      <td>0.966797</td>\n",
       "      <td>0.991699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991699</td>\n",
       "      <td>40.0</td>\n",
       "      <td>49.75</td>\n",
       "      <td>54.0</td>\n",
       "      <td>56.25</td>\n",
       "      <td>60.0</td>\n",
       "      <td>52.00000</td>\n",
       "      <td>0.264893</td>\n",
       "      <td>0.329590</td>\n",
       "      <td>0.357666</td>\n",
       "      <td>0.373291</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>0.344971</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>899.5</td>\n",
       "      <td>900.5</td>\n",
       "      <td>902.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>71.5000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>95.50</td>\n",
       "      <td>101.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>101.5000</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.632324</td>\n",
       "      <td>0.668945</td>\n",
       "      <td>0.709961</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.673340</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.75</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>150.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>plate1_H6_S45</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CommonBrain</td>\n",
       "      <td>-29.937500</td>\n",
       "      <td>-13.429688</td>\n",
       "      <td>-9.273438</td>\n",
       "      <td>-5.765625</td>\n",
       "      <td>6.453125</td>\n",
       "      <td>-10.265625</td>\n",
       "      <td>-27.781250</td>\n",
       "      <td>-13.164062</td>\n",
       "      <td>-8.382812</td>\n",
       "      <td>-3.667969</td>\n",
       "      <td>8.984375</td>\n",
       "      <td>-8.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2083500</td>\n",
       "      <td>2084250</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>3.184573</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>76.75</td>\n",
       "      <td>92.5</td>\n",
       "      <td>105.25</td>\n",
       "      <td>151.0</td>\n",
       "      <td>96.6875</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.653809</td>\n",
       "      <td>0.704102</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723145</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>62.15625</td>\n",
       "      <td>0.410645</td>\n",
       "      <td>0.438232</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.520996</td>\n",
       "      <td>0.469238</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>88.50</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.8125</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.50</td>\n",
       "      <td>84.5</td>\n",
       "      <td>86.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>84.8125</td>\n",
       "      <td>0.556152</td>\n",
       "      <td>0.589355</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>0.677734</td>\n",
       "      <td>0.716309</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>119.0</td>\n",
       "      <td>127.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>143.75</td>\n",
       "      <td>151.0</td>\n",
       "      <td>133.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>plate1_G2_S13</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CommonBrain</td>\n",
       "      <td>-29.156250</td>\n",
       "      <td>-14.843750</td>\n",
       "      <td>-9.179688</td>\n",
       "      <td>-5.277344</td>\n",
       "      <td>7.703125</td>\n",
       "      <td>-10.218750</td>\n",
       "      <td>-28.953125</td>\n",
       "      <td>-12.953125</td>\n",
       "      <td>-8.640625</td>\n",
       "      <td>-5.238281</td>\n",
       "      <td>9.867188</td>\n",
       "      <td>-9.593750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Chromosome    Start      End  n_fwd  n_rev  n_proper_pairs  n_ref_reads  \\\n",
       "61        chr1  1568750  1569500      0      4               4            0   \n",
       "63        chr1  1569000  1569750      0      5               5            0   \n",
       "65        chr1  1569250  1570000      0      4               4            0   \n",
       "83        chr1  1770000  1770750      1      3               3            0   \n",
       "344       chr1  2083500  2084250      0      6               0            0   \n",
       "\n",
       "     3end_gini  5end_gini  max_mapq  n_reads       rpm  orientation_bias  \\\n",
       "61    0.000039   0.000045        60        4  2.237463              1.00   \n",
       "63    0.000047   0.000053        60        5  2.796829              1.00   \n",
       "65    0.000036   0.000036        60        4  2.237463              1.00   \n",
       "83    0.000051   0.000019        60        4  2.400610              0.75   \n",
       "344   0.000003   0.000010        60        6  3.184573              1.00   \n",
       "\n",
       "     frac_proper_pairs  alignment_score_q0  alignment_score_q0.25  \\\n",
       "61                1.00                96.0                 137.25   \n",
       "63                1.00                96.0                 150.00   \n",
       "65                1.00               150.0                 150.75   \n",
       "83                0.75               146.0                 149.75   \n",
       "344               0.00                63.0                  76.75   \n",
       "\n",
       "     alignment_score_q0.5  alignment_score_q0.75  alignment_score_q1  \\\n",
       "61                  151.0                 151.00               151.0   \n",
       "63                  151.0                 151.00               151.0   \n",
       "65                  151.0                 151.00               151.0   \n",
       "83                  151.0                 151.00               151.0   \n",
       "344                  92.5                 105.25               151.0   \n",
       "\n",
       "     alignment_score_mean  alignment_score_normed_q0  \\\n",
       "61               137.2500                   0.635742   \n",
       "63               139.7500                   0.635742   \n",
       "65               150.7500                   0.993164   \n",
       "83               149.7500                   0.966797   \n",
       "344               96.6875                   0.552734   \n",
       "\n",
       "     alignment_score_normed_q0.25  alignment_score_normed_q0.5  \\\n",
       "61                       0.909180                     1.000000   \n",
       "63                       0.993164                     1.000000   \n",
       "65                       0.998535                     1.000000   \n",
       "83                       0.991699                     1.000000   \n",
       "344                      0.653809                     0.704102   \n",
       "\n",
       "     alignment_score_normed_q0.75  alignment_score_normed_q1  \\\n",
       "61                       1.000000                        1.0   \n",
       "63                       1.000000                        1.0   \n",
       "65                       1.000000                        1.0   \n",
       "83                       1.000000                        1.0   \n",
       "344                      0.732422                        1.0   \n",
       "\n",
       "     alignment_score_normed_mean  L1_alignment_score_q0  \\\n",
       "61                      0.909180                   59.0   \n",
       "63                      0.925781                   59.0   \n",
       "65                      0.998535                   59.0   \n",
       "83                      0.991699                   40.0   \n",
       "344                     0.723145                   62.0   \n",
       "\n",
       "     L1_alignment_score_q0.25  L1_alignment_score_q0.5  \\\n",
       "61                      59.75                     60.0   \n",
       "63                      60.00                     60.0   \n",
       "65                      59.75                     60.0   \n",
       "83                      49.75                     54.0   \n",
       "344                     62.00                     62.0   \n",
       "\n",
       "     L1_alignment_score_q0.75  L1_alignment_score_q1  L1_alignment_score_mean  \\\n",
       "61                      60.25                   61.0                 60.00000   \n",
       "63                      61.00                   62.0                 60.40625   \n",
       "65                      60.50                   62.0                 60.25000   \n",
       "83                      56.25                   60.0                 52.00000   \n",
       "344                     62.00                   63.0                 62.15625   \n",
       "\n",
       "     L1_alignment_score_normed_q0  L1_alignment_score_normed_q0.25  \\\n",
       "61                       0.390625                         0.395752   \n",
       "63                       0.390625                         0.397461   \n",
       "65                       0.390625                         0.395752   \n",
       "83                       0.264893                         0.329590   \n",
       "344                      0.410645                         0.438232   \n",
       "\n",
       "     L1_alignment_score_normed_q0.5  L1_alignment_score_normed_q0.75  \\\n",
       "61                         0.397461                         0.398926   \n",
       "63                         0.397461                         0.404053   \n",
       "65                         0.397461                         0.400635   \n",
       "83                         0.357666                         0.373291   \n",
       "344                        0.486328                         0.488281   \n",
       "\n",
       "     L1_alignment_score_normed_q1  L1_alignment_score_normed_mean  \\\n",
       "61                       0.404053                        0.397461   \n",
       "63                       0.410645                        0.399902   \n",
       "65                       0.410645                        0.398926   \n",
       "83                       0.399902                        0.344971   \n",
       "344                      0.520996                        0.469238   \n",
       "\n",
       "     L1_reference_start_q0  L1_reference_start_q0.25  L1_reference_start_q0.5  \\\n",
       "61                   839.0                     839.0                    839.0   \n",
       "63                   839.0                     839.0                    839.0   \n",
       "65                   839.0                     839.0                    839.0   \n",
       "83                   839.0                     839.0                    839.0   \n",
       "344                  839.0                     839.0                    839.0   \n",
       "\n",
       "     L1_reference_start_q0.75  L1_reference_start_q1  L1_reference_start_mean  \\\n",
       "61                      839.0                  839.0                    839.0   \n",
       "63                      839.0                  839.0                    839.0   \n",
       "65                      839.0                  839.0                    839.0   \n",
       "83                      839.0                  839.0                    839.0   \n",
       "344                     839.0                  839.0                    839.0   \n",
       "\n",
       "     L1_reference_end_q0  L1_reference_end_q0.25  L1_reference_end_q0.5  \\\n",
       "61                 899.0                   899.0                  899.0   \n",
       "63                 899.0                   899.0                  899.0   \n",
       "65                 899.0                   899.0                  899.0   \n",
       "83                 879.0                   894.0                  899.5   \n",
       "344                902.0                   902.0                  902.0   \n",
       "\n",
       "     L1_reference_end_q0.75  L1_reference_end_q1  L1_reference_end_mean  \\\n",
       "61                    899.0                900.0                  899.0   \n",
       "63                    900.0                902.0                  900.0   \n",
       "65                    900.0                902.0                  900.0   \n",
       "83                    900.5                902.0                  895.0   \n",
       "344                   902.0                902.0                  902.0   \n",
       "\n",
       "     L1_Acount_q0  L1_Acount_q0.25  L1_Acount_q0.5  L1_Acount_q0.75  \\\n",
       "61           76.0             76.0            76.0            76.25   \n",
       "63           76.0             76.0            76.0            77.00   \n",
       "65           76.0             76.0            76.0            76.50   \n",
       "83           64.0             68.5            71.0            74.00   \n",
       "344          78.0             86.0            86.5            88.50   \n",
       "\n",
       "     L1_Acount_q1  L1_Acount_mean  mate_alignment_score_q0  \\\n",
       "61           77.0         76.2500                     87.0   \n",
       "63           78.0         76.6250                     87.0   \n",
       "65           78.0         76.5000                     88.0   \n",
       "83           80.0         71.5000                     88.0   \n",
       "344          89.0         85.8125                     80.0   \n",
       "\n",
       "     mate_alignment_score_q0.25  mate_alignment_score_q0.5  \\\n",
       "61                        87.75                       88.0   \n",
       "63                        88.00                       88.0   \n",
       "65                        88.00                       88.0   \n",
       "83                        95.50                      101.0   \n",
       "344                       82.50                       84.5   \n",
       "\n",
       "     mate_alignment_score_q0.75  mate_alignment_score_q1  \\\n",
       "61                         88.0                     88.0   \n",
       "63                         88.0                     94.0   \n",
       "65                         89.5                     94.0   \n",
       "83                        107.0                    116.0   \n",
       "344                        86.5                     91.0   \n",
       "\n",
       "     mate_alignment_score_mean  mate_alignment_score_normed_q0  \\\n",
       "61                     87.7500                        0.576172   \n",
       "63                     89.0000                        0.576172   \n",
       "65                     89.5000                        0.583008   \n",
       "83                    101.5000                        0.583008   \n",
       "344                    84.8125                        0.556152   \n",
       "\n",
       "     mate_alignment_score_normed_q0.25  mate_alignment_score_normed_q0.5  \\\n",
       "61                            0.581055                          0.583008   \n",
       "63                            0.583008                          0.583008   \n",
       "65                            0.583008                          0.583008   \n",
       "83                            0.632324                          0.668945   \n",
       "344                           0.589355                          0.659180   \n",
       "\n",
       "     mate_alignment_score_normed_q0.75  mate_alignment_score_normed_q1  \\\n",
       "61                            0.583008                        0.583008   \n",
       "63                            0.583008                        0.622559   \n",
       "65                            0.592773                        0.622559   \n",
       "83                            0.709961                        0.773438   \n",
       "344                           0.677734                        0.716309   \n",
       "\n",
       "     mate_alignment_score_normed_mean  mate_read_length_q0  \\\n",
       "61                           0.581055                151.0   \n",
       "63                           0.589355                151.0   \n",
       "65                           0.592773                151.0   \n",
       "83                           0.673340                150.0   \n",
       "344                          0.640137                119.0   \n",
       "\n",
       "     mate_read_length_q0.25  mate_read_length_q0.5  mate_read_length_q0.75  \\\n",
       "61                   151.00                  151.0                  151.00   \n",
       "63                   151.00                  151.0                  151.00   \n",
       "65                   151.00                  151.0                  151.00   \n",
       "83                   150.75                  151.0                  151.00   \n",
       "344                  127.00                  127.5                  143.75   \n",
       "\n",
       "     mate_read_length_q1  mate_read_length_mean  num_supp_alignments_q0  \\\n",
       "61                 151.0                 151.00                     1.0   \n",
       "63                 151.0                 151.00                     1.0   \n",
       "65                 151.0                 151.00                     0.0   \n",
       "83                 151.0                 150.75                     0.0   \n",
       "344                151.0                 133.50                     1.0   \n",
       "\n",
       "     num_supp_alignments_q0.25  num_supp_alignments_q0.5  \\\n",
       "61                         1.0                       1.0   \n",
       "63                         1.0                       1.0   \n",
       "65                         0.0                       0.0   \n",
       "83                         0.0                       0.0   \n",
       "344                        1.0                       1.0   \n",
       "\n",
       "     num_supp_alignments_q0.75  num_supp_alignments_q1  \\\n",
       "61                         1.0                     1.0   \n",
       "63                         1.0                     1.0   \n",
       "65                         0.0                     0.0   \n",
       "83                         0.0                     0.0   \n",
       "344                        1.0                     1.0   \n",
       "\n",
       "     num_supp_alignments_mean        cell_id  xtea_id   xtea  \\\n",
       "61                        1.0  plate1_D3_S18       -1  False   \n",
       "63                        1.0  plate1_D3_S18       -1  False   \n",
       "65                        0.0  plate1_D3_S18       -1  False   \n",
       "83                        0.0  plate1_H6_S45       -1  False   \n",
       "344                       1.0  plate1_G2_S13       -1  False   \n",
       "\n",
       "     xtea_1kb_3end_id  xtea_1kb_3end  xtea_20kb   L1HS  L1HS_1kb_3end  \\\n",
       "61                 -1          False      False  False          False   \n",
       "63                 -1          False      False  False          False   \n",
       "65                 -1          False      False  False          False   \n",
       "83                 -1          False      False  False          False   \n",
       "344                -1          False      False  False          False   \n",
       "\n",
       "     L1HS_20kb  L1PA2  L1PA2_1kb_3end  L1PA2_20kb  L1PA3  L1PA3_1kb_3end  \\\n",
       "61       False  False           False       False  False           False   \n",
       "63       False  False           False       False  False           False   \n",
       "65       False  False           False       False  False           False   \n",
       "83       False  False           False       False  False           False   \n",
       "344      False  False           False       False  False           False   \n",
       "\n",
       "     L1PA3_20kb  L1PA4  L1PA4_1kb_3end  L1PA4_20kb  L1PA5  L1PA5_1kb_3end  \\\n",
       "61        False  False           False       False  False           False   \n",
       "63        False  False           False       False  False           False   \n",
       "65        False  False           False       False  False           False   \n",
       "83        False  False           False       False  False           False   \n",
       "344       False  False           False       False  False           False   \n",
       "\n",
       "     L1PA5_20kb  L1PA6  L1PA6_1kb_3end  L1PA6_20kb     donor_id  pos_score_q0  \\\n",
       "61        False  False           False       False  CommonBrain    -28.390625   \n",
       "63        False  False           False       False  CommonBrain    -28.390625   \n",
       "65        False  False           False       False  CommonBrain    -28.390625   \n",
       "83        False  False           False       False  CommonBrain    -29.937500   \n",
       "344       False  False           False       False  CommonBrain    -29.156250   \n",
       "\n",
       "     pos_score_q0.25  pos_score_q0.5  pos_score_q0.75  pos_score_q1  \\\n",
       "61        -13.484375       -9.273438        -5.898438      7.179688   \n",
       "63        -13.609375       -9.062500        -5.261719      7.179688   \n",
       "65        -14.296875       -8.742188        -4.417969      9.867188   \n",
       "83        -13.429688       -9.273438        -5.765625      6.453125   \n",
       "344       -14.843750       -9.179688        -5.277344      7.703125   \n",
       "\n",
       "     pos_score_mean  neg_score_q0  neg_score_q0.25  neg_score_q0.5  \\\n",
       "61       -10.109375    -29.203125       -13.476562       -8.796875   \n",
       "63        -9.929688    -29.203125       -13.726562       -8.812500   \n",
       "65        -9.421875    -29.203125       -14.492188       -8.929688   \n",
       "83       -10.265625    -27.781250       -13.164062       -8.382812   \n",
       "344      -10.218750    -28.953125       -12.953125       -8.640625   \n",
       "\n",
       "     neg_score_q0.75  neg_score_q1  neg_score_mean  \n",
       "61         -4.843750      7.929688       -9.500000  \n",
       "63         -5.054688      7.929688       -9.671875  \n",
       "65         -5.128906      7.914062      -10.125000  \n",
       "83         -3.667969      8.984375       -8.765625  \n",
       "344        -5.238281      9.867188       -9.593750  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metadata\n",
    "meta = pd.read_csv(\n",
    "    \"/iblm/logglun02/mcuoco/workflows/sz_slavseq/config/slavseq_metadata.tsv\", sep=\"\\t\"\n",
    ")\n",
    "meta.columns = [col.lower() for col in meta.columns]\n",
    "donors = pd.read_csv(\n",
    "    \"/iblm/logglun02/mcuoco/workflows/sz_slavseq/config/all_donors.tsv\", sep=\"\\t\"\n",
    ")\n",
    "cells = pd.read_csv(\n",
    "    \"/iblm/logglun02/mcuoco/workflows/sz_slavseq/config/all_samples.tsv\", sep=\"\\t\"\n",
    ")\n",
    "cells = pd.merge(cells, donors, on=\"donor_id\", how=\"left\")\n",
    "cells = pd.merge(\n",
    "    cells, meta[[\"tissue_id\", \"sequencing\", \"region\"]], on=\"tissue_id\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train xgboost model on one tissue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['3end_gini', '5end_gini', 'orientation_bias', 'frac_proper_pairs', 'alignment_score_normed_mean', 'L1_alignment_score_normed_mean', 'L1_reference_start_mean', 'L1_reference_end_mean', 'L1_Acount_mean', 'mate_alignment_score_normed_mean', 'num_supp_alignments_mean', 'rpm']\n"
     ]
    }
   ],
   "source": [
    "# define features\n",
    "features = []\n",
    "keys = [\"_mean\", \"frac\", \"gini\", \"bias\"]\n",
    "for c in data.columns:\n",
    "    if (\"_score\" in c) or (\"_length\" in c):\n",
    "        if \"_normed\" not in c:\n",
    "            continue\n",
    "    for k in keys:\n",
    "        if k in c:\n",
    "            features.append(c)\n",
    "features.append(\"rpm\")\n",
    "print(\"Features:\", features)\n",
    "\n",
    "# define the classifier\n",
    "# TODO: ask to optimize scale_pos_weight\n",
    "from flaml import AutoML\n",
    "\n",
    "clf = AutoML(\n",
    "    task=\"classification\",\n",
    "    estimator_list=[\"xgboost\"],\n",
    "    early_stop=True,\n",
    "    time_budget=120,  # time budget in seconds, 120 is good for CommonBrain, have tried larger but best model is usually found in <120s\n",
    "    metric=\"ap\",\n",
    "    skip_transform=True,  # don't preprocess data\n",
    "    auto_augment=False,  # don't augment rare classes\n",
    "    starting_points=\"static\",  # use data-independent hyperparameterstarting points\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "# setup outdir\n",
    "Path(\"model_logs\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "\n",
      "\t\tTuning model with 12 features on 517160 windows\n",
      "\t\t29649 positive windows (7487 loci)\n",
      "\t\t487511 negative windows\n",
      "\t\t18 Chromosomes: ['chr1' 'chr10' 'chr12' 'chr13' 'chr15' 'chr16' 'chr17' 'chr18' 'chr19'\n",
      " 'chr2' 'chr20' 'chr22' 'chr3' 'chr5' 'chr6' 'chr7' 'chr8' 'chr9']\n",
      "\t\t1 Donors: ['CommonBrain']\n",
      "\t\t101 cells\n",
      "\t\t\n",
      "[flaml.automl.logger: 08-23 15:08:56] {1679} INFO - task = classification\n",
      "[flaml.automl.logger: 08-23 15:08:56] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-23 15:08:56] {1788} INFO - Minimizing error metric: 1-ap\n",
      "[flaml.automl.logger: 08-23 15:08:56] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-23 15:08:56] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:08:56] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "[flaml.automl.logger: 08-23 15:09:03] {2344} INFO - Estimated sufficient time budget=68309s. Estimated necessary time budget=68s.\n",
      "[flaml.automl.logger: 08-23 15:09:03] {2391} INFO -  at 6.9s,\testimator xgboost's best error=0.5572,\tbest estimator xgboost's best error=0.5572\n",
      "[flaml.automl.logger: 08-23 15:09:03] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:09:03] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}\n",
      "[flaml.automl.logger: 08-23 15:09:10] {2391} INFO -  at 14.1s,\testimator xgboost's best error=0.5454,\tbest estimator xgboost's best error=0.5454\n",
      "[flaml.automl.logger: 08-23 15:09:10] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:09:10] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999981, 'learning_rate': 0.09999999999999995, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.9999999999999992}\n",
      "[flaml.automl.logger: 08-23 15:09:17] {2391} INFO -  at 21.5s,\testimator xgboost's best error=0.5454,\tbest estimator xgboost's best error=0.5454\n",
      "[flaml.automl.logger: 08-23 15:09:17] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:09:17] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 27.123547475701166, 'learning_rate': 0.14971979531690346, 'subsample': 0.9246883402776725, 'colsample_bylevel': 0.898014219139486, 'colsample_bytree': 0.9238615531554782, 'reg_alpha': 0.0012834136471904583, 'reg_lambda': 8.519631194693332}\n",
      "[flaml.automl.logger: 08-23 15:09:24] {2391} INFO -  at 28.6s,\testimator xgboost's best error=0.5318,\tbest estimator xgboost's best error=0.5318\n",
      "[flaml.automl.logger: 08-23 15:09:24] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:09:24] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 3.815612027960904, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180926}\n",
      "[flaml.automl.logger: 08-23 15:09:35] {2391} INFO -  at 39.0s,\testimator xgboost's best error=0.4762,\tbest estimator xgboost's best error=0.4762\n",
      "[flaml.automl.logger: 08-23 15:09:35] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:09:35] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 1.2029602487741256, 'learning_rate': 0.020472781437872928, 'subsample': 0.9619193128258086, 'colsample_bylevel': 0.6332640992103601, 'colsample_bytree': 0.8426061861774259, 'reg_alpha': 0.001314342238891819, 'reg_lambda': 12.61531256373696}\n",
      "[flaml.automl.logger: 08-23 15:09:45] {2391} INFO -  at 49.4s,\testimator xgboost's best error=0.4762,\tbest estimator xgboost's best error=0.4762\n",
      "[flaml.automl.logger: 08-23 15:09:45] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:09:45] {805} INFO - trial 1 config: {'n_estimators': 12, 'max_leaves': 8, 'min_child_weight': 12.102557139985414, 'learning_rate': 0.07274503562018719, 'subsample': 1.0, 'colsample_bylevel': 0.9964307229150408, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.420431242553656}\n",
      "[flaml.automl.logger: 08-23 15:10:09] {2391} INFO -  at 73.4s,\testimator xgboost's best error=0.4598,\tbest estimator xgboost's best error=0.4598\n",
      "[flaml.automl.logger: 08-23 15:10:09] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:10:09] {805} INFO - trial 1 config: {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 24.65057645900532, 'learning_rate': 0.18678090989345658, 'subsample': 1.0, 'colsample_bylevel': 0.8775478343453571, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0015851927568202393, 'reg_lambda': 10.814535413902005}\n",
      "[flaml.automl.logger: 08-23 15:10:43] {2391} INFO -  at 106.7s,\testimator xgboost's best error=0.4056,\tbest estimator xgboost's best error=0.4056\n",
      "[flaml.automl.logger: 08-23 15:10:49] {2627} INFO - retrain xgboost for 6.2s\n",
      "[flaml.automl.logger: 08-23 15:10:49] {2630} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=0.8775478343453571, colsample_bynode=None,\n",
      "              colsample_bytree=0.8499027725496043, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.18678090989345658, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=6,\n",
      "              min_child_weight=24.65057645900532, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=23, n_jobs=-1,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-23 15:10:49] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-23 15:10:49] {1931} INFO - Time taken to find the best model: 106.71729612350464\n",
      "Fold 2/5\n",
      "\n",
      "\t\tTuning model with 12 features on 496653 windows\n",
      "\t\t28475 positive windows (7177 loci)\n",
      "\t\t468178 negative windows\n",
      "\t\t18 Chromosomes: ['chr1' 'chr11' 'chr12' 'chr14' 'chr15' 'chr16' 'chr17' 'chr18' 'chr19'\n",
      " 'chr20' 'chr21' 'chr22' 'chr3' 'chr4' 'chr5' 'chr6' 'chr7' 'chr9']\n",
      "\t\t1 Donors: ['CommonBrain']\n",
      "\t\t101 cells\n",
      "\t\t\n",
      "[flaml.automl.logger: 08-23 15:10:54] {1679} INFO - task = classification\n",
      "[flaml.automl.logger: 08-23 15:10:54] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-23 15:10:54] {1788} INFO - Minimizing error metric: 1-ap\n",
      "[flaml.automl.logger: 08-23 15:10:54] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-23 15:10:54] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:10:54] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "[flaml.automl.logger: 08-23 15:11:01] {2344} INFO - Estimated sufficient time budget=66338s. Estimated necessary time budget=66s.\n",
      "[flaml.automl.logger: 08-23 15:11:01] {2391} INFO -  at 6.6s,\testimator xgboost's best error=0.5405,\tbest estimator xgboost's best error=0.5405\n",
      "[flaml.automl.logger: 08-23 15:11:01] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:11:01] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}\n",
      "[flaml.automl.logger: 08-23 15:11:08] {2391} INFO -  at 13.6s,\testimator xgboost's best error=0.5405,\tbest estimator xgboost's best error=0.5405\n",
      "[flaml.automl.logger: 08-23 15:11:08] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:11:08] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}\n",
      "[flaml.automl.logger: 08-23 15:11:15] {2391} INFO -  at 20.9s,\testimator xgboost's best error=0.5113,\tbest estimator xgboost's best error=0.5113\n",
      "[flaml.automl.logger: 08-23 15:11:15] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:11:15] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}\n",
      "[flaml.automl.logger: 08-23 15:11:22] {2391} INFO -  at 27.9s,\testimator xgboost's best error=0.4977,\tbest estimator xgboost's best error=0.4977\n",
      "[flaml.automl.logger: 08-23 15:11:22] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.tune.tune: 08-23 15:11:22] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}\n"
     ]
    }
   ],
   "source": [
    "from scripts.pyslavseq.model_selection import Model\n",
    "\n",
    "mdl = Model(\n",
    "    clf=clf,\n",
    "    data=data,\n",
    "    features=features,\n",
    "    label_col=\"xtea_1kb_3end\",\n",
    "    rpm_filter=5,\n",
    "    outfile=f\"model_logs/CommonBrain10.log\",\n",
    ")\n",
    "mdl.cv(n_splits=5)\n",
    "results = mdl.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    results.explode([\"precision\", \"adjusted_locus_recall\"]),\n",
    "    x=\"adjusted_locus_recall\",\n",
    "    y=\"precision\",\n",
    "    hue=\"fold\",\n",
    "    col=\"stage\",\n",
    "    kind=\"line\",\n",
    ").set(xlim=(0, 1), ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze distribution of false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    results.explode([\"precision\", \"threshold\"]),\n",
    "    x=\"threshold\",\n",
    "    y=\"precision\",\n",
    "    hue=\"fold\",\n",
    "    col=\"stage\",\n",
    "    kind=\"line\",\n",
    ").set(xlim=(0, 1), ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest, chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are certain loci overrepresented in FP?\n",
    "loci = [c for c in data.columns if (\"kb\" in c) and (\"id\" not in c)]\n",
    "\n",
    "res = []\n",
    "for prob in np.linspace(0.1, 0.9, 9):\n",
    "    fp_df = mdl.data[(mdl.data[\"proba\"] > prob) & (mdl.data[\"xtea_1kb_3end\"] == False)]\n",
    "    for anno in loci:\n",
    "        p = (\n",
    "            mdl.data[anno].sum() / mdl.data.shape[0]\n",
    "        )  # proportion of loci with annotation in background\n",
    "        test = binomtest(\n",
    "            fp_df[anno].sum(), n=fp_df.shape[0], p=p, alternative=\"greater\"\n",
    "        )\n",
    "        res.append(\n",
    "            {\n",
    "                \"proba\": prob,\n",
    "                \"anno\": anno,\n",
    "                \"p\": test.pvalue,\n",
    "                \"-log10(p)\": np.log10(test.pvalue) * -1,\n",
    "            }\n",
    "        )\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "g = sns.lineplot(data=res, x=\"proba\", y=\"-log10(p)\", hue=\"anno\")\n",
    "g.set(\n",
    "    title=\"Binomial test for enrichment of annotations in CommonBrain FPs\",\n",
    "    xlabel=\"Probability threshold\",\n",
    "    ylabel=\"-log10(p)\",\n",
    ")\n",
    "g.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = mdl.data[(mdl.data[\"proba\"] > 0.5) & (mdl.data[\"xtea_1kb_3end\"] == False)]\n",
    "print(f\"{fp_df['xtea_20kb'].sum()}/{fp_df.shape[0]} FPs are in xtea_20kb regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at some examples in IGV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the FPs with 20kb of an xtea\n",
    "fp_df[fp_df[\"xtea_20kb\"]][[\"Chromosome\", \"Start\", \"End\", \"cell_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one, find the insertion\n",
    "data[\n",
    "    (data[\"xtea_1kb_3end\"])\n",
    "    & (data[\"Chromosome\"] == \"chr1\")\n",
    "    & (data[\"Start\"] > 74e6)\n",
    "    & (data[\"Start\"] < 75e6)\n",
    "][[\"Chromosome\", \"Start\", \"End\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all cells with FPs near this insertion\n",
    "cells = fp_df[\n",
    "    fp_df[\"xtea_20kb\"]\n",
    "    & (fp_df[\"Chromosome\"] == \"chr1\")\n",
    "    & (fp_df[\"Start\"] >= 74725e3)\n",
    "    & (fp_df[\"Start\"] < 74745e3)\n",
    "][\"cell_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY IN IGV\n",
    "import tempfile, shutil, igv_jupyter, os\n",
    "\n",
    "# make temp directory, all data must be in jupyter filetree\n",
    "tmpdir = tempfile.TemporaryDirectory(prefix=f\"{os.getcwd()}/igv_data_\")\n",
    "\n",
    "# make list to store tracks for IGV\n",
    "track_list = []\n",
    "\n",
    "vcf = \"/iblm/netapp/data4/mcuoco/wgs-te-pipeline/results/xtea/illumina_10x/CommonBrain/L1.vcf\"\n",
    "shutil.copy(vcf, tmpdir.name)\n",
    "\n",
    "rel_name = Path(tmpdir.name).name\n",
    "track = {\n",
    "    \"name\": \"xTEA calls\",\n",
    "    \"url\": f\"{rel_name}/{Path(vcf).name}\",\n",
    "    \"type\": \"variant\",\n",
    "    \"indexed\": \"False\",\n",
    "}\n",
    "track_list.append(track)\n",
    "\n",
    "for c in cells:\n",
    "    file = f\"../results/align/CommonBrain/{c}.tagged.sorted.bam\"\n",
    "    assert Path(file).exists(), f\"{file} does not exist\"\n",
    "    # copy to tempdir\n",
    "    shutil.copy(file, tmpdir.name)\n",
    "    shutil.copy(file + \".bai\", tmpdir.name)\n",
    "    track = {\n",
    "        \"name\": c,\n",
    "        \"path\": f\"{rel_name}/{Path(file).name}\",\n",
    "        \"type\": \"alignment\",\n",
    "        \"indexed\": True,\n",
    "        \"displayMode\": \"SQUISHED\",\n",
    "    }\n",
    "    track_list.append(track)\n",
    "\n",
    "# start IGV (https://github.com/igvteam/igv-notebook)\n",
    "igv_jupyter.init()\n",
    "igv_browser = igv_jupyter.Browser(\n",
    "    {\"genome\": \"hg38\", \"locus\": \"chr1:74715500-74735500\", \"tracks\": track_list}\n",
    ")\n",
    "igv_browser.to_svg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close tempdir\n",
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screenshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- add image  -->\n",
    "chr1:74721000-7473300\n",
    "![chr1:74721000-7473300](./chr1_fp_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df[\n",
    "    (fp_df[\"xtea_20kb\"])\n",
    "    & (fp_df[\"Chromosome\"] == \"chr9\")\n",
    "    & (fp_df[\"Start\"] > 102306e3)\n",
    "    & (fp_df[\"Start\"] < 102330e3)\n",
    "    & (fp_df[\"cell_id\"].str.contains(\"plate2_H\"))\n",
    "][[\"Chromosome\", \"Start\", \"End\", \"cell_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chr9:102306000-102330000\n",
    "![chr9:102306000-102330000](./chr9_fp_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average max_mapq\n",
    "print(\"background average max_mapq:\", mdl.data[\"max_mapq\"].mean())\n",
    "print(\"fp average max_mapq:\", fp_df[\"max_mapq\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many FP windows are adjacent vs singleton?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
