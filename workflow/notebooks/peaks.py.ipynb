{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyranges as pr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in ref and non-ref insertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the rmsk file\n",
    "rmsk = pd.read_csv(\n",
    "    snakemake.input.rmsk[0],\n",
    "    skiprows=3,\n",
    "    delim_whitespace=True,\n",
    "    names=[\"Chromosome\", \"Start\", \"End\", \"Strand\", \"repeat\"],\n",
    "    usecols=[4, 5, 6, 8, 9],\n",
    ")\n",
    "# filter for rep_names\n",
    "rep_names = [\n",
    "    \"L1HS_3end\",\n",
    "    \"L1PA2_3end\",\n",
    "    \"L1PA3_3end\",\n",
    "    \"L1PA4_3end\",\n",
    "    \"L1PA5_3end\",\n",
    "    \"L1PA6_3end\",\n",
    "]\n",
    "rmsk = rmsk[rmsk[\"repeat\"].isin(rep_names)]\n",
    "rmsk[\"Strand\"] = rmsk.apply(lambda x: \"+\" if x.Strand == \"+\" else \"-\", axis=1)\n",
    "rmsk = pr.PyRanges(rmsk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "knrgl = pd.read_csv(\n",
    "    snakemake.input.knrgl[0],\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"Chromosome\", \"Start\", \"End\", \"Strand\", \"SVLEN\", \"SVTYPE\"],\n",
    "    dtype={\"Chromosome\": str, \"Start\": int, \"End\": int},\n",
    ")\n",
    "knrgl[\"Start\"] = knrgl.apply(\n",
    "    lambda x: x.Start - 750 if x.Strand == \"-\" else x.Start, axis=1\n",
    ")\n",
    "knrgl[\"End\"] = knrgl.apply(lambda x: x.End + 750 if x.Strand == \"+\" else x.End, axis=1)\n",
    "knrgl = pr.PyRanges(knrgl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Peak:\n",
    "    \"\"\"Store collection of reads in a peak\"\"\"\n",
    "\n",
    "    def __init__(self, r):\n",
    "        self.chr = r.reference_name\n",
    "        self.start = r.reference_start\n",
    "        self.end = r.reference_end\n",
    "        self.is_reverse = not r.is_reverse if r.is_read1 else r.is_reverse\n",
    "        self.width = self.end - self.start\n",
    "        if r.is_read1:\n",
    "            self.r1 = [r]\n",
    "            self.r1_ends = [r.query_alignment_end]\n",
    "            self.r2 = []\n",
    "            self.r2_starts = []\n",
    "        elif r.is_read2:\n",
    "            self.r1 = []\n",
    "            self.r1_ends = []\n",
    "            self.r2 = [r]\n",
    "            self.r2_starts = [r.query_alignment_start]\n",
    "        self.coverage = np.ones(r.reference_end - r.reference_start)\n",
    "        assert self.end >= self.start, f\"Peak end={self.end} < start={self.start}\"\n",
    "\n",
    "    def add_read(self, r):\n",
    "        \"\"\"Add read to peak, extending peak if necessary\"\"\"\n",
    "\n",
    "        if r.is_read1:\n",
    "            self.r1.append(r)\n",
    "            self.r1_ends.append(r.query_alignment_end)\n",
    "        elif r.is_read2:\n",
    "            self.r2.append(r)\n",
    "            self.r2_starts.append(r.query_alignment_start)\n",
    "\n",
    "        # extend peak\n",
    "        if r.reference_end > self.end:\n",
    "            self.coverage = np.append(\n",
    "                self.coverage, np.zeros(r.reference_end - self.end)\n",
    "            )\n",
    "            self.end = r.reference_end\n",
    "            self.width = self.end - self.start\n",
    "\n",
    "        start = r.reference_start - self.start\n",
    "        end = r.reference_end - self.start\n",
    "        self.coverage[start:end] += 1\n",
    "\n",
    "        assert self.end >= self.start, f\"Peak end={self.end} < start={self.start}\"\n",
    "        return self\n",
    "\n",
    "    def merge(self, p):\n",
    "        \"\"\"Merge with another peak\"\"\"\n",
    "        for r in p.r1:\n",
    "            self.add_read(r)\n",
    "        for r in p.r2:\n",
    "            self.add_read(r)\n",
    "            \n",
    "        assert self.end >= self.start, f\"Peak end={self.end} < start={self.start}\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76fd291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_peaks(peaks):\n",
    "\t'''Visualize initial peak calls'''\n",
    "\tdf = {\n",
    "\t\t\"Chromosome\": [],\n",
    "\t\t\"Start\": [],\n",
    "\t\t\"End\": [],\n",
    "\t\t\"nreads\": [],\n",
    "\t\t\"width\": [],\n",
    "\t\t\"dist to next peak\": [],\n",
    "\t}\n",
    "\n",
    "\t# iterate over peaks, collecting stats\n",
    "\tfor i, p in enumerate(peaks):\n",
    "\t\tdf[\"Chromosome\"].append(p.chr)\n",
    "\t\tdf[\"Start\"].append(p.start)\n",
    "\t\tdf[\"End\"].append(p.end)\n",
    "\t\tdf[\"nreads\"].append(len(p.r1))\n",
    "\t\tdf[\"width\"].append(p.width)\n",
    "\t\tif i < len(peaks) - 1 and p.chr == peaks[i + 1].chr:\n",
    "\t\t\tdf[\"dist to next peak\"].append(peaks[i + 1].start - p.start)\n",
    "\t\telse:\n",
    "\t\t\tdf[\"dist to next peak\"].append(np.nan)\n",
    "\n",
    "\t# convert to dataframe\n",
    "\tdf = pd.DataFrame.from_records(df).set_index([\"Chromosome\", \"Start\", \"End\"])\n",
    "\n",
    "\t# add rmsk and knrgl labels\n",
    "\tdf_rmsk = pr.PyRanges(df.reset_index()).overlap(rmsk).df.set_index([\"Chromosome\", \"Start\", \"End\"])\n",
    "\tdf_knrgl = pr.PyRanges(df.reset_index()).overlap(knrgl).df.set_index([\"Chromosome\", \"Start\", \"End\"])\n",
    "\tdf[\"rmsk\"] = df.index.isin(df_rmsk.index)\n",
    "\tdf[\"knrgl\"] = df.index.isin(df_knrgl.index)\n",
    "\tdf[\"label\"] = df.apply(lambda x: \"rmsk\" if x.rmsk else \"knrgl\" if x.knrgl else \"other\", axis=1)\n",
    "\t\n",
    "\t# plot\n",
    "\tfig = sns.JointGrid(data=df.reset_index(), x=\"width\", y=\"nreads\", hue=\"label\", marginal_ticks=True)\n",
    "\tfig.plot_joint(sns.scatterplot, alpha = 0.5)\n",
    "\tfig.ax_joint.set(yscale = \"log\")\n",
    "\n",
    "\tfig.plot_marginals(sns.histplot, bins=100, element=\"step\", fill=False)\n",
    "\tfig.ax_marg_x.set(yscale = \"log\")\n",
    "\tfig.ax_marg_y.set(xscale = \"log\")\n",
    "\tfig.ax_joint.set(xlabel = \"Peak width (bp)\", ylabel = \"Number of reads\")\n",
    "\tplt.show()\n",
    "\t\n",
    "\tfig = sns.histplot(data=df.reset_index(), x = \"dist to next peak\", bins=1000)\n",
    "\tfig.set(xscale = \"log\", xlabel = \"Distance to next peak (bp)\", ylabel = \"Count\", xlim=(1, max(df[\"dist to next peak\"])))\n",
    "\tplt.show()\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making non-ref L1 peaks from high-quality R1 reads...\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: make peaks from highest quality read1 alignments\n",
    "bam = pysam.AlignmentFile(snakemake.input.bam, \"rb\")  # must be coordinate sorted\n",
    "peaks = []; p = None\n",
    "print(\"Making non-ref L1 peaks from high-quality R1 reads...\")\n",
    "for r in bam.fetch():\n",
    "\n",
    "    # make peaks from read1 if\n",
    "    # 1. is a read1 primary alignment\n",
    "    # 2. mate aligns better to L1 than reference genome (YA >20, YA>YG)\n",
    "    # 3. has high mapping quality (60), indicating it's uniquely mapped\n",
    "    if (\n",
    "        r.is_read1\n",
    "        and (not r.is_unmapped)\n",
    "        and (not r.is_secondary)\n",
    "        and (not r.is_supplementary)\n",
    "        and (r.has_tag(\"YA\") and r.has_tag(\"YG\"))\n",
    "        and (r.get_tag(\"YA\") > 20 and r.get_tag(\"YA\") > r.get_tag(\"YG\"))\n",
    "        and (not r.has_tag(\"XA\")) \t\n",
    "        and (r.mapping_quality >= 60)\n",
    "    ):\n",
    "\n",
    "        # initialize\n",
    "        if p is None:\n",
    "            p = Peak(r)\n",
    "\n",
    "        # if has mate in peak or overlap with peak, add to peak\n",
    "        elif (\n",
    "            (r.reference_name == p.chr)\n",
    "            and (\n",
    "                (r.is_read1 and (r.is_reverse != p.is_reverse))\n",
    "                or (r.is_read2 and (r.is_reverse == p.is_reverse))\n",
    "            )\n",
    "            and (r.get_overlap(p.start, p.end) > r.query_alignment_length / 3)\n",
    "        ):\n",
    "            p.add_read(r)\n",
    "\n",
    "        # else, make new peak\n",
    "        else:\n",
    "            peaks.append(p)\n",
    "            p = Peak(r)\n",
    "bam.close()\n",
    "\n",
    "print(f\"Found {len(peaks)} non-ref L1 peaks\")\n",
    "df = visualize_peaks(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering other reads at these peaks...\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: gather additional features for each peak\n",
    "print(\"Gathering other reads at these peaks...\")\n",
    "bam = pysam.AlignmentFile(snakemake.input.bam, \"rb\")  \n",
    "for p in peaks:\n",
    "    for r in bam.fetch(p.chr, p.start, p.end):\n",
    "        if not r.is_unmapped:\n",
    "            p.add_read(r)\n",
    "\n",
    "bam.close()\n",
    "df = visualize_peaks(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76003"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# from https://github.com/oliviaguest/gini/blob/master/gini.py\n",
    "def gini(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
    "    # based on bottom eq:\n",
    "    # http://www.statsdirect.com/help/generatedimages/equations/equation154.svg\n",
    "    # from:\n",
    "    # http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm\n",
    "    # All values are treated equally, arrays must be 1d:\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        # Values cannot be negative:\n",
    "        array -= np.amin(array)\n",
    "    # Values cannot be 0:\n",
    "    array = array + 0.0000001\n",
    "    # Values must be sorted:\n",
    "    array = np.sort(array)\n",
    "    # Index per array element:\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    # Number of array elements:\n",
    "    n = array.shape[0]\n",
    "    # Gini coefficient:\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))\n",
    "\n",
    "# STEP 3: merge peaks that are close together\n",
    "print(\"Merging peaks that are close together...\")\n",
    "for i, p in enumerate(peaks):\n",
    "\tif i > 0 and p.chr == peaks[i-1].chr:\n",
    "\t\tif gini(p.coverage) < gini(p.merge(peaks[i-1]).coverage): # TODO save p.merge and use that, dont call merge twice\n",
    "\t\t\tp = p.merge(peaks[i-1])\n",
    "\t\t\tpeaks[i-1] = None\n",
    "\n",
    "new_peaks = []\n",
    "for p in peaks:\n",
    "\tif p is not None:\n",
    "\t\tnew_peaks.append(p)\n",
    "\n",
    "print(f\"{len(new_peaks)} remain after merging\")\n",
    "df = visualize_peaks(new_peaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3836aa1a9d51decadc262ede625600e3d1503a5094d0df8672d74fbcecc91b58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
