{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.7.12 (conda)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -p /raidixshare_log-g/mcuoco/workflows/sz_slavseq/.snakemake/conda/3af65f4365e9c54635c0474856608874 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "__author__ = 'Ricardo S Jacomini'\n",
    "\n",
    "import argparse\n",
    "import sys,gc\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.collections import QuadMesh\n",
    "import seaborn as sn\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.setrecursionlimit(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posix.uname_result(sysname='Linux', nodename='vm6', release='5.6.7-arch1-1', version='#1 SMP PREEMPT Thu, 23 Apr 2020 09:13:56 +0000', machine='x86_64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.uname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ceph/projects/slavseq_sz_4k/fastq/cutadapt/bwamem/rmdup/tags/tabix/features/flank_features/folds/slavseq_metadata/RandomForest/somaticMutationSummary/validade_debug/_h'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTest:\n",
    "    def __init__(self, sample=None, exp=\"\", input_type=\"pickle\"):\n",
    "        self.sample = sample\n",
    "        self.exp = exp\n",
    "        self.input_type = input_type\n",
    "        self.accurary_train = 0\n",
    "        self.accurary_test = 0\n",
    "\n",
    "    def train_classifier(self, features, labels):\n",
    "        cla = RandomForestClassifier(bootstrap=True,\n",
    "                                     n_estimators=100,\n",
    "                                     oob_score=True,\n",
    "                                     n_jobs=-1)\n",
    "\n",
    "        cla.fit(features, labels)\n",
    "        return cla\n",
    "\n",
    "    def create_directory(self, directory):\n",
    "        import os, errno\n",
    "\n",
    "        try:\n",
    "            os.makedirs(directory)\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "    def openDictionary(self, dict_data, outPut, Idx=['chrom','start','end','cell_id'], printLoad=False):\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        csv_columns = dict_data.keys()\n",
    "\n",
    "        if printLoad == True: print(\"Loading :\")\n",
    "\n",
    "        for data in csv_columns:\n",
    "\n",
    "            if printLoad == True: print(\"        \" + data)\n",
    "            dict_data[data] = pd.read_csv(outPut + data + '.csv', sep=\",\", index_col=Idx)\n",
    "\n",
    "        return dict_data\n",
    "\n",
    "    def openDictionary_pickle(self, dict_data, outPut, printLoad=False):\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "\n",
    "        csv_columns = dict_data.keys()\n",
    "\n",
    "        if printLoad == True: print(\"Loading :\")\n",
    "\n",
    "        for data in csv_columns:\n",
    "\n",
    "            if printLoad == True: print(\"        \" + data)\n",
    "            dict_data[data] = pd.read_pickle(outPut + data + '.pickle.gz', compression='gzip')\n",
    "\n",
    "        return dict_data\n",
    "\n",
    "    def get_labelencode(self, df):\n",
    "\n",
    "        le = LabelEncoder()\n",
    "\n",
    "        classes = list(set(df))\n",
    "\n",
    "        le.fit(classes)\n",
    "\n",
    "        return le, le.fit_transform(df)\n",
    "\n",
    "    def get_labelencode_inverse(self, le, df):\n",
    "\n",
    "        return list(le.inverse_transform(df))\n",
    "\n",
    "    def get_ypred(self, y_pred, proba, all_reads, le):\n",
    "\n",
    "        df = y_pred.copy()\n",
    "\n",
    "        df['all_reads_count'] = all_reads\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        for (a, b) in zip(le.classes_, proba):\n",
    "            df[a + \"_proba\"] = proba[b]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_groups(self, df):\n",
    "        return df.groupby(['Y'], axis=0).size()\n",
    "\n",
    "    def run_train_test(self, features, pred, phase, model=None, le=None, labels=None):\n",
    "\n",
    "        if phase == \"Training\": model = self.train_classifier(features, labels)\n",
    "\n",
    "        predictions = model.predict(features)\n",
    "\n",
    "        df = accuracy_score(labels, predictions, sample_weight=None)\n",
    "\n",
    "        proba = model.predict_proba(features)\n",
    "\n",
    "        pred['Y_pred'] = self.get_labelencode_inverse(le, predictions)\n",
    "\n",
    "        pred = self.get_ypred(pred, pd.DataFrame(proba), features['all_reads.count'], le)\n",
    "\n",
    "        log_stdout = open(self.fileFold + \"%s_report_performance.txt\" % phase, \"w\")\n",
    "        print(\"\\n Report performance %s\" % phase)\n",
    "        self.report_performance(model, features, labels, predictions, log_stdout, phase, le)\n",
    "\n",
    "        log_stdout = open(self.fileFold + \"%s_report_feature_importance.txt\" % phase, \"w\")\n",
    "        print(\"\\n Report feature importance\")\n",
    "        self.report_feature_importances(model, features.columns, log_stdout)\n",
    "\n",
    "        return df, pred, model\n",
    "\n",
    "    def run(self, num_folds):\n",
    "\n",
    "        print(\"Sample %s\" % self.sample)\n",
    "\n",
    "        for fold in range(num_folds):\n",
    "\n",
    "            self.fileFold = set([str(Path(f).parent) for f in snakemake.output if re.search(f'fold_{fold}', f)]).pop()\n",
    "\n",
    "            if not Path(self.fileFold).exists():\n",
    "\n",
    "                self.create_directory(self.fileFold)\n",
    "\n",
    "                # clear_output()\n",
    "\n",
    "                # Loading dataset ------------------------------------------------------------------------------------\n",
    "\n",
    "                train_x, train_y, test_x, test_y = self.get_sample( path_files + self.fileFold )\n",
    "\n",
    "                le, labels = self.get_labelencode(train_y['Y'])\n",
    "\n",
    "                # classes\n",
    "                self.classes = list(le.classes_)\n",
    "\n",
    "                if self.get_groups(train_y).count() != self.get_groups(test_y).count():\n",
    "                    log_stdout = open(self.sample + \"_has_no_equal_classes.txt\", \"w\")\n",
    "                    print(\"\\nThis cell (%s) fold (%i) has no enough classes to classifier... \" % (self.sample, k),\n",
    "                          file=log_stdout, flush=True)\n",
    "                    print(\"\\nTrain classes (%d) - Test classes (%d)\" % (\n",
    "                    self.get_groups(train_y).count(), self.get_groups(test_y).count()), file=log_stdout, flush=True)\n",
    "                    continue\n",
    "\n",
    "                    # Training the model -----------------------------------------------------------------------------\n",
    "\n",
    "                print(\"\\nTraining the model... \")\n",
    "\n",
    "                Train, df, trained_model = self.run_train_test(train_x.copy(), train_y.copy(),\n",
    "                                                               phase='Training',\n",
    "                                                               le=le,\n",
    "                                                               labels=labels)\n",
    "\n",
    "                df.to_csv(self.fileFold + \"/Training_y_pred.csv\", sep=';', index=False, header=True)\n",
    "\n",
    "                # Testing the model ----------------------------------------------------------------------------------\n",
    "\n",
    "                print(\"\\nTesting the model... \")\n",
    "\n",
    "                le, labels = self.get_labelencode(test_y['Y'])\n",
    "                Test, df, trained_model = self.run_train_test(test_x.copy(), test_y.copy(), phase='Testing',\n",
    "                                                              model=trained_model, le=le, labels=labels)\n",
    "\n",
    "                df.to_csv(self.fileFold + \"/Testing_y_pred.csv\", sep=';', index=False, header=True)\n",
    "\n",
    "                # report sys.out --- \n",
    "                print(\"\\nTrain Accuracy :: {} - Test Accuracy  :: {}\".format(Train, Test))\n",
    "\n",
    "                self.accurary_train = Train\n",
    "                self.accurary_test = Test\n",
    "\n",
    "                # saving ------------------------------------------------------------------------------------------ \n",
    "                print(\"\\nSaving...\")\n",
    "\n",
    "                df = pd.DataFrame(data=None, columns={'Train', 'Test'}, dtype='float64')\n",
    "\n",
    "                df = df.append([{'Train': Train, 'Test': Test}])\n",
    "                df.to_csv(self.fileFold + \"/Train_Test_Accuracy.csv\", sep=';', index=False, header=True)\n",
    "\n",
    "        print(\"%s : finishing\" % (self.sample))\n",
    "\n",
    "    def get_sample(self, fn):\n",
    "\n",
    "        print(\"Processing cell ({})... \\n\".format(self.sample))\n",
    "\n",
    "        print(\"Loading dataset...\")\n",
    "\n",
    "        df = {\"X_train\": None, \"X_test\": None, \"Y_train\": None, \"Y_test\": None}\n",
    "\n",
    "        if self.input_type == \"csv\":\n",
    "            TrainTest = self.openDictionary(df, fn)\n",
    "            train_y = TrainTest[\"Y_train\"].rename(columns={'0': 'Y'})\n",
    "            test_y = TrainTest[\"Y_test\"].rename(columns={'0': 'Y'})\n",
    "        else:\n",
    "            TrainTest = self.openDictionary_pickle(df, fn)\n",
    "            train_y = TrainTest[\"Y_train\"].to_frame('Y')\n",
    "            test_y = TrainTest[\"Y_test\"].to_frame('Y')\n",
    "\n",
    "        train_x = TrainTest[\"X_train\"]\n",
    "        test_x = TrainTest[\"X_test\"]\n",
    "\n",
    "        # Train and Test dataset size details\n",
    "        print(\"Train_x Shape :: \", train_x.shape)\n",
    "        print(\"Train_y Shape :: \", train_y.shape)\n",
    "        print(\"Test_x Shape :: \", test_x.shape)\n",
    "        print(\"Test_y Shape :: \", test_y.shape)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        return train_x, train_y, test_x, test_y\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Sample %s - Tain Accuracy: %s - Test Accuracy %s \" % (\n",
    "        self.sample, self.accurary_train, self.accurary_test)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.sample)\n",
    "\n",
    "    @classmethod\n",
    "    def get_classname(cls):\n",
    "        return cls.__name__\n",
    "\n",
    "    def use_classname(self):\n",
    "        return self.get_classname()\n",
    "\n",
    "    def report_feature_importances(self, cla, feature_names, log_stdout):\n",
    "        ii = np.argsort(cla.feature_importances_)\n",
    "        print(\"Feature importance:\", file=log_stdout, flush=True)\n",
    "        for i in range(len(ii)):\n",
    "            print('', '\\t'.join([str(cla.feature_importances_[ii[i]]), feature_names[ii[i]]]), file=log_stdout,\n",
    "                  flush=True)\n",
    "        print(file=log_stdout, flush=True)\n",
    "\n",
    "    def report_performance(self, cla, features, labels, pred, log_stdout, title, le):\n",
    "\n",
    "        class_names = cla.classes_\n",
    "        cnf_matrix = confusion_matrix(labels, pred)\n",
    "\n",
    "        acc = np.trace(cnf_matrix) / float(np.sum(cnf_matrix))\n",
    "        pred_val_axis = 'x'\n",
    "        cmap = 'Oranges'\n",
    "        fz = 10\n",
    "        figsize = [5, 5]\n",
    "\n",
    "        show_null_values = 2\n",
    "        # cols_names = [\"RL1\",\"KNRGL\",\"OTHER\"]\n",
    "        cols_names = list(le.classes_)\n",
    "\n",
    "        df_cm = pd.DataFrame(cnf_matrix, index=cols_names, columns=cols_names)\n",
    "\n",
    "        self.pretty_plot_confusion_matrix(df_cm, accuracy=acc, fz=fz, cmap=cmap, figsize=figsize,\n",
    "                                          show_null_values=show_null_values,\n",
    "                                          pred_val_axis=pred_val_axis,\n",
    "                                          title=('Confusion matrix (%s) ' % title),\n",
    "                                          fn=self.fileFold + title + '_Confusion-pretty.png')\n",
    "\n",
    "        self.plot_confusion_matrix(cnf_matrix,\n",
    "                                   title=('Confusion matrix (%s), without normalization' % title),\n",
    "                                   fn=self.fileFold + title + '_Confusion.png')\n",
    "\n",
    "        self.plot_confusion_matrix(cnf_matrix, normalize=True,\n",
    "                                   title=('Normalized confusion matrix (%s)' % title),\n",
    "                                   fn=self.fileFold + title + '_Confusion-Normalized.png')\n",
    "\n",
    "        print(\"Classifier:\", file=log_stdout, flush=True)\n",
    "        print(cla, file=log_stdout, flush=True)\n",
    "        print(file=log_stdout, flush=True)\n",
    "        print((\"%s set confusion matrix:\" % title), file=log_stdout, flush=True)\n",
    "\n",
    "        print(cnf_matrix, file=log_stdout, flush=True)\n",
    "        print(file=log_stdout, flush=True)\n",
    "\n",
    "        # https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "        # https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "        print(\"Cross-validation metrics:\", file=log_stdout, flush=True)\n",
    "        for jj in ['precision', 'recall', 'f1']:\n",
    "\n",
    "            if jj == 'precision':\n",
    "                scores = precision_score(labels, pred, average='weighted')\n",
    "            elif jj == 'recall':\n",
    "                scores = recall_score(labels, pred, average='weighted')\n",
    "            else:\n",
    "                scores = f1_score(labels, pred, average='weighted')\n",
    "\n",
    "            print('', jj, scores, file=log_stdout, flush=True)\n",
    "\n",
    "            print('\\t', 'mean', jj, scores.mean(), file=log_stdout, flush=True)\n",
    "            print('\\t', 'std', jj, scores.std(), file=log_stdout, flush=True)\n",
    "\n",
    "        print(file=log_stdout, flush=True)\n",
    "\n",
    "    def plot_confusion_matrix(self, cm,\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Blues, fn=\"cm\"):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        print(cm)\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(self.classes))\n",
    "        plt.xticks(tick_marks, self.classes, rotation=45)\n",
    "        plt.yticks(tick_marks, self.classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        plt.savefig(fn, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def configcell_text_and_colors(self, array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0):\n",
    "        \"\"\"\n",
    "          config cell text and colors\n",
    "          and return text elements to add and to dell\n",
    "          @TODO: use fmt\n",
    "        \"\"\"\n",
    "        text_add = []\n",
    "        text_del = []\n",
    "        cell_val = array_df[lin][col]\n",
    "        tot_all = array_df[-1][-1]\n",
    "        per = (float(cell_val) / tot_all) * 100\n",
    "        curr_column = array_df[:, col]\n",
    "        ccl = len(curr_column)\n",
    "\n",
    "        # last line  and/or last column\n",
    "        if (col == (ccl - 1)) or (lin == (ccl - 1)):\n",
    "            # tots and percents\n",
    "            if cell_val != 0:\n",
    "                if (col == ccl - 1) and (lin == ccl - 1):\n",
    "                    tot_rig = 0\n",
    "                    for i in range(array_df.shape[0] - 1):\n",
    "                        tot_rig += array_df[i][i]\n",
    "                    per_ok = (float(tot_rig) / cell_val) * 100\n",
    "                elif col == ccl - 1:\n",
    "                    tot_rig = array_df[lin][lin]\n",
    "                    per_ok = (float(tot_rig) / cell_val) * 100\n",
    "                elif lin == ccl - 1:\n",
    "                    tot_rig = array_df[col][col]\n",
    "                    per_ok = (float(tot_rig) / cell_val) * 100\n",
    "                per_err = 100 - per_ok\n",
    "            else:\n",
    "                per_ok = per_err = 0\n",
    "\n",
    "            per_ok_s = ['%.2f%%' % per_ok, '100%'][per_ok == 100]\n",
    "\n",
    "            # text to DEL\n",
    "            text_del.append(oText)\n",
    "\n",
    "            # text to ADD\n",
    "            font_prop = fm.FontProperties(weight='bold', size=fz)\n",
    "            text_kwargs = dict(color='w', ha=\"center\", va=\"center\", gid='sum', fontproperties=font_prop)\n",
    "            lis_txt = ['%d' % cell_val, per_ok_s, '%.2f%%' % per_err]\n",
    "            lis_kwa = [text_kwargs]\n",
    "            dic = text_kwargs.copy()\n",
    "            dic['color'] = 'g'\n",
    "            lis_kwa.append(dic)\n",
    "            dic = text_kwargs.copy()\n",
    "            dic['color'] = 'r'\n",
    "            lis_kwa.append(dic)\n",
    "            lis_pos = [(oText._x, oText._y - 0.3), (oText._x, oText._y), (oText._x, oText._y + 0.3)]\n",
    "            for i in range(len(lis_txt)):\n",
    "                newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i], kw=lis_kwa[i])\n",
    "                # print 'lin: %s, col: %s, newText: %s' %(lin, col, newText)\n",
    "                text_add.append(newText)\n",
    "            # print '\\n'\n",
    "\n",
    "            # set background color for sum cells (last line and last column)\n",
    "            carr = [0.27, 0.30, 0.27, 1.0]\n",
    "            if (col == ccl - 1) and (lin == ccl - 1):\n",
    "                carr = [0.17, 0.20, 0.17, 1.0]\n",
    "            facecolors[posi] = carr\n",
    "\n",
    "        else:\n",
    "            if per > 0:\n",
    "                txt = '%s\\n%.2f%%' % (cell_val, per)\n",
    "            else:\n",
    "                if show_null_values == 0:\n",
    "                    txt = ''\n",
    "                elif show_null_values == 1:\n",
    "                    txt = '0'\n",
    "                else:\n",
    "                    txt = '0\\n0.0%'\n",
    "            oText.set_text(txt)\n",
    "\n",
    "            # main diagonal\n",
    "            if col == lin:\n",
    "                # set color of the text in the diagonal to white\n",
    "                oText.set_color('w')\n",
    "                # set background color in the diagonal to blue\n",
    "                facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
    "            else:\n",
    "                oText.set_color('r')\n",
    "\n",
    "        return text_add, text_del\n",
    "\n",
    "\n",
    "    def insert_totals(self, df_cm):\n",
    "        \"\"\" insert total column and line (the last ones) \"\"\"\n",
    "        sum_col = []\n",
    "        for c in df_cm.columns:\n",
    "            sum_col.append(df_cm[c].sum())\n",
    "        sum_lin = []\n",
    "        for item_line in df_cm.iterrows():\n",
    "            sum_lin.append(item_line[1].sum())\n",
    "        df_cm['total_rows'] = sum_lin\n",
    "        sum_col.append(np.sum(sum_lin))\n",
    "        df_cm.loc['total_cols'] = sum_col\n",
    "        # print ('\\ndf_cm:\\n', df_cm, '\\n\\b\\n')\n",
    "\n",
    "    def get_new_fig(self, fn, figsize=[9, 9]):\n",
    "        \"\"\" Init graphics \"\"\"\n",
    "        fig1 = plt.figure(fn, figsize)\n",
    "        ax1 = fig1.gca()  # Get Current Axis\n",
    "        ax1.cla()  # clear existing plot\n",
    "        return fig1, ax1\n",
    "\n",
    "    #\n",
    "    # https://github.com/wcipriano/pretty-print-confusion-matrix/blob/master/confusion_matrix_pretty_print.py\n",
    "    def pretty_plot_confusion_matrix(self, df_cm, accuracy=None, annot=True, cmap=\"Oranges\", fmt='.2f', fz=11,\n",
    "                                     lw=0.5, cbar=False, figsize=[8, 8], show_null_values=0, pred_val_axis='y',\n",
    "                                     title='Confusion matrix', fn=\"cm\"):\n",
    "        \"\"\"\n",
    "          print conf matrix with default layout (like matlab)\n",
    "          params:\n",
    "          df_cm          dataframe (pandas) without totals\n",
    "          annot          print text in each cell\n",
    "          cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
    "          fz             fontsize\n",
    "          lw             linewidth\n",
    "          pred_val_axis  where to show the prediction values (x or y axis)\n",
    "                         'col' or 'x': show predicted values in columns (x axis) instead lines\n",
    "                         'lin' or 'y': show predicted values in lines   (y axis)\n",
    "        \"\"\"\n",
    "        if pred_val_axis in ('col', 'x'):\n",
    "            xlbl = 'Predicted label'\n",
    "            ylbl = 'Actual label'\n",
    "        else:\n",
    "            xlbl = 'Actual label'\n",
    "            ylbl = 'Predicted label'\n",
    "            df_cm = df_cm.T\n",
    "\n",
    "        # create \"Total\" column\n",
    "        self.insert_totals(df_cm)\n",
    "\n",
    "        if cmap is None:\n",
    "            cmap = plt.get_cmap('Blues')\n",
    "\n",
    "        # this is for print always in the same window\n",
    "        fig, ax1 = self.get_new_fig('Conf matrix default', figsize)\n",
    "\n",
    "        # thanks for seaborn\n",
    "        ax = sn.heatmap(df_cm, annot=annot, annot_kws={\"size\": fz}, linewidths=lw, ax=ax1,\n",
    "                        cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt)\n",
    "\n",
    "        # set ticklabels rotation\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=10)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation=25, fontsize=10)\n",
    "\n",
    "        # Turn off all the ticks\n",
    "        for t in ax.xaxis.get_major_ticks():\n",
    "            t.tick1On = False\n",
    "            t.tick2On = False\n",
    "        for t in ax.yaxis.get_major_ticks():\n",
    "            t.tick1On = False\n",
    "            t.tick2On = False\n",
    "\n",
    "        # face colors list\n",
    "        quadmesh = ax.findobj(QuadMesh)[0]\n",
    "        facecolors = quadmesh.get_facecolors()\n",
    "\n",
    "        # iter in text elements\n",
    "        array_df = np.array(df_cm.to_records(index=False).tolist())\n",
    "        text_add = []\n",
    "        text_del = []\n",
    "        posi = -1  # from left to right, bottom to top.\n",
    "        for t in ax.collections[0].axes.texts:  # ax.texts:\n",
    "            pos = np.array(t.get_position()) - [0.5, 0.5]\n",
    "            lin = int(pos[1])\n",
    "            col = int(pos[0])\n",
    "            posi += 1\n",
    "            # print ('>>> pos: %s, posi: %s, val: %s, txt: %s' %(pos, posi, array_df[lin][col], t.get_text()))\n",
    "\n",
    "            # set text\n",
    "            txt_res = self.configcell_text_and_colors(array_df, lin, col, t, facecolors, posi, fz, fmt,\n",
    "                                                      show_null_values)\n",
    "\n",
    "            text_add.extend(txt_res[0])\n",
    "            text_del.extend(txt_res[1])\n",
    "\n",
    "        # remove the old ones\n",
    "        for item in text_del:\n",
    "            item.remove()\n",
    "        # append the new ones\n",
    "        for item in text_add:\n",
    "            ax.text(item['x'], item['y'], item['text'], **item['kw'])\n",
    "\n",
    "        # titles and legends\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(xlbl)\n",
    "        ax.set_ylabel(ylbl)\n",
    "\n",
    "        plt.xlabel('Predicted label\\nAccuracy={:0.4f}; Misclass={:0.4f}'.format(accuracy, 1 - accuracy))\n",
    "        plt.tight_layout()  # set layout slim\n",
    "\n",
    "        plt.savefig(fn, bbox_inches='tight')\n",
    "        plt.close()       \n",
    "\n",
    "    def plot_confusion_matrix(self, cm,\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Blues, fn=\"cm\"):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        print(cm)\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(self.classes))\n",
    "        plt.xticks(tick_marks, self.classes, rotation=45)\n",
    "        plt.yticks(tick_marks, self.classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        plt.savefig(fn, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(path_file='../../../_m/'):\n",
    "    files = [f.name for f in os.scandir(path_file) if f.is_dir()]\n",
    "    files.sort()\n",
    "    files = [value for value in files if value not in ['.ipynb_checkpoints', '.snakemake', '.snakemake.old']]\n",
    "\n",
    "    return files\n",
    "\n",
    "def print_err(msg):\n",
    "    sys.stderr.write(msg + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "train_test = TrainTest(snakemake.wildcards.donor)\n",
    "train_test.run(snakemake.params.num_folds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d605e60d61377715ecce460aaa39cf8db69180f5f955993bbc97b1647a7406f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
