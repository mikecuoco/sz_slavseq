{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cef9d5",
   "metadata": {},
   "source": [
    "# Analyze fastq and bam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a62d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ab632a",
   "metadata": {},
   "source": [
    "## Reads the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d75269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "def parse_fastqc(zip_path):\n",
    "    \"\"\"\n",
    "    Parse fastqc report, return df of each metric\n",
    "    \"\"\"\n",
    "\n",
    "    # get data from zip\n",
    "    with ZipFile(zip_path, \"r\") as z:\n",
    "        for file in z.namelist():\n",
    "            if \"fastqc_data.txt\" in file:\n",
    "                with z.open(file) as f:\n",
    "                    lines = f.read().decode(\"utf-8\").splitlines()\n",
    "                    break\n",
    "\n",
    "    # Create a dictionary to hold data for each module\n",
    "    data, headers = {}, {}\n",
    "    module = None\n",
    "    for line in lines:\n",
    "        if line.startswith(\">>\") and \"END_MODULE\" not in line:\n",
    "            module = line.lstrip(\">>\").split(\"\\t\")[0]\n",
    "            data[module] = []\n",
    "        elif module and line.startswith(\"#\"):\n",
    "            headers[module] = line.strip().lstrip(\"#\").split(\"\\t\")\n",
    "        elif module and not line.startswith(\">>\") and line.strip():\n",
    "            values = line.strip().split(\"\\t\")\n",
    "            data[module].append(values)\n",
    "\n",
    "    # Convert each module's data to a DataFrame\n",
    "    dfs = {}\n",
    "    for module, content in data.items():\n",
    "        if content:\n",
    "            df = pd.DataFrame(content, columns=headers[module])\n",
    "            if \"Measure\" in headers[module]:\n",
    "                df.set_index(\"Measure\", inplace=True)\n",
    "\n",
    "            # try converting each column to numeric\n",
    "            for c in df.columns:\n",
    "                if c == \"Length\":\n",
    "                    df[c] = df[c].str.split(\"-\").str[0].astype(int)\n",
    "\n",
    "                try:\n",
    "                    df[c] = pd.to_numeric(df[c])\n",
    "                except ValueError:\n",
    "                    df[c] = df[c]\n",
    "\n",
    "            dfs[module] = df\n",
    "\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def parse_flagstat(file):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "\n",
    "    return {\n",
    "        \"mapped\": int(lines[0].split()[0]),\n",
    "        \"pcr_duplicates\": int(lines[3].split()[0]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7565f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(list)\n",
    "\n",
    "# fastq metrics\n",
    "print(\"Reading fastqc\")\n",
    "for f in tqdm(snakemake.input.fastqc):\n",
    "    sample = \"_\".join(Path(f).name.split(\"_\")[:-1])\n",
    "    read = Path(f).name.split(\"_\")[-1].split(\".\")[0]\n",
    "    stage = Path(f).name.split(\"_\")[-1].split(\".\")[1]\n",
    "    dfs = parse_fastqc(f)\n",
    "    df = dfs[\"Sequence Length Distribution\"]\n",
    "    avg_length = (df[\"Length\"] * df[\"Count\"]).sum() / df[\"Count\"].sum()\n",
    "    df = dfs[\"Per sequence quality scores\"]\n",
    "    avg_qual = (df[\"Quality\"] * df[\"Count\"]).sum() / df[\"Count\"].sum()\n",
    "\n",
    "    res[\"sample\"].append(sample)\n",
    "    res[\"read\"].append(read)\n",
    "    res[\"stage\"].append(stage)\n",
    "    res[\"n_reads\"].append(dfs[\"Basic Statistics\"].loc[\"Total Sequences\", \"Value\"])\n",
    "    # res[\"avg_length\"].append(avg_length)\n",
    "    # res[\"avg_quality\"].append(avg_qual)\n",
    "\n",
    "\n",
    "# bam metrics\n",
    "print(\"Reading flagstats\")\n",
    "for f in tqdm(snakemake.input.flagstat):\n",
    "    sample = Path(f).name.rstrip(\".tagged.sorted.flagstat.txt\")\n",
    "    flagstat = parse_flagstat(f)\n",
    "    # add total reads from sample\n",
    "    res[\"sample\"].append(sample)\n",
    "    res[\"stage\"].append(\"mapped\")\n",
    "    res[\"read\"].append(\"NA\")\n",
    "    res[\"n_reads\"].append(flagstat[\"mapped\"])\n",
    "\n",
    "    # add deduplicated reads from sample\n",
    "    res[\"sample\"].append(sample)\n",
    "    res[\"stage\"].append(\"dedup\")\n",
    "    res[\"read\"].append(\"NA\")\n",
    "    res[\"n_reads\"].append(flagstat[\"mapped\"] - flagstat[\"pcr_duplicates\"])\n",
    "\n",
    "res = pd.DataFrame(res)\n",
    "res[\"n_reads\"] = pd.to_numeric(res[\"n_reads\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0381a6a",
   "metadata": {},
   "source": [
    "## Inspect Number of reads per cell at fastq level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_nreads(df):\n",
    "    stage = df[\"stage\"].unique()[0]\n",
    "    if stage in [\"raw\", \"trimmed\", \"filtered\"]:\n",
    "        nreads = df[df[\"read\"].isin([\"R1\", \"merged\", \"R2\"])][\"n_reads\"].sum()\n",
    "    else:\n",
    "        nreads = df[\"n_reads\"].unique()[0]\n",
    "    return nreads\n",
    "\n",
    "\n",
    "nreads = (\n",
    "    res.groupby([\"sample\", \"stage\"]).apply(summarize_nreads).reset_index(name=\"nreads\")\n",
    ")\n",
    "\n",
    "# remove bulk samples\n",
    "nreads = nreads.query(\"'gDNA' not in sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.histplot(\n",
    "    nreads,\n",
    "    x=\"nreads\",\n",
    "    hue=\"stage\",\n",
    "    alpha=0.5,\n",
    "    bins=70,\n",
    "    hue_order=[\"raw\", \"trimmed\", \"filtered\", \"mapped\", \"pcr_dedup\"],\n",
    "    log_scale=(True, False),\n",
    "    ax=ax1,\n",
    ")\n",
    "ax1.set_ylabel(\"# cells\")\n",
    "\n",
    "sns.ecdfplot(\n",
    "    nreads,\n",
    "    x=\"nreads\",\n",
    "    hue=\"stage\",\n",
    "    stat=\"count\",\n",
    "    hue_order=[\"raw\", \"trimmed\", \"filtered\", \"mapped\", \"pcr_dedup\"],\n",
    "    log_scale=(True, False),\n",
    "    ax=ax2,\n",
    ")\n",
    "# set log scale\n",
    "ax2.set_ylabel(\"# cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_diff(df):\n",
    "    raw = df.loc[df[\"stage\"] == \"raw\", \"nreads\"].unique()[0]\n",
    "    trimmed = df.loc[df[\"stage\"] == \"trimmed\", \"nreads\"].unique()[0]\n",
    "    filtered = df.loc[df[\"stage\"] == \"filtered\", \"nreads\"].unique()[0]\n",
    "    total = df.loc[df[\"stage\"] == \"mapped\", \"nreads\"].unique()[0]\n",
    "    dedup = df.loc[df[\"stage\"] == \"pcr_dedup\", \"nreads\"].unique()[0]\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"trimmed\": (raw - trimmed) / raw,\n",
    "            \"filtered\": (trimmed - filtered) / trimmed,\n",
    "            \"mapped\": (filtered - mapped) / filtered,\n",
    "            \"pcr_dedup\": (mapped - pcr_dedup) / mapped,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "sdiff = (\n",
    "    nreads.groupby(\"sample\")\n",
    "    .apply(stage_diff)\n",
    "    .reset_index()\n",
    "    .melt(id_vars=\"sample\", var_name=\"stage\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0499f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 5), sharey=True)\n",
    "\n",
    "# Define the order\n",
    "\n",
    "cat_type = CategoricalDtype(\n",
    "    categories=[\"raw\", \"trimmed\", \"filtered\", \"mapped\", \"pcr_dedup\"], ordered=True\n",
    ")\n",
    "sdiff[\"stage\"] = sdiff[\"stage\"].astype(cat_type)\n",
    "nreads[\"stage\"] = nreads[\"stage\"].astype(cat_type)\n",
    "\n",
    "# lineplot\n",
    "for sample, df in tqdm(nreads.groupby(\"sample\")):\n",
    "    sns.lineplot(\n",
    "        df,\n",
    "        x=\"nreads\",\n",
    "        y=\"stage\",\n",
    "        alpha=0.3,\n",
    "        ax=ax1,\n",
    "        c=\"blue\",\n",
    "    )\n",
    "\n",
    "ax1.set_xscale(\"log\")\n",
    "\n",
    "# striplot\n",
    "sns.boxenplot(sdiff, y=\"stage\", x=\"value\", ax=ax2)\n",
    "ax2.set_xlabel(\"fraction of reads lost from previous step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d83a0",
   "metadata": {},
   "source": [
    "## Inspect sequencing saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute duplication rate for library saturation\n",
    "def saturation(df):\n",
    "    total = df.loc[df[\"stage\"] == \"mapped\", \"nreads\"].unique()[0]\n",
    "    dups = total - df.loc[df[\"stage\"] == \"pcr_dedup\", \"nreads\"].unique()[0]\n",
    "    return dups / total\n",
    "\n",
    "\n",
    "sat = nreads.groupby(\"sample\").apply(saturation)\n",
    "\n",
    "g = sns.histplot(sat, bins=70)\n",
    "g.set_xlabel(\"Sequencing Saturation (Duplicated / Total Reads)\")\n",
    "g.set_ylabel(\"# cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0c18c",
   "metadata": {},
   "source": [
    "TODO:\n",
    "1. show contig stats\n",
    "2. look at correlations with clinical features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
