{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings, math\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyranges as pr\n",
    "from pyslavseq.preprocessing import collate_labels, df2tabix\n",
    "from pyslavseq.plotting import datashader_plot\n",
    "\n",
    "HUE_ORDER = [\"KNRGL\", \"OTHER\", \"KRGL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(snakemake.config[\"donors\"], sep=\"\\t\", dtype={\"donor_id\": str})  # type: ignore\n",
    "\n",
    "bdata, ldata, mdata = [], [], []\n",
    "l1hs = pr.read_bed(snakemake.input.l1hs)\n",
    "for b, m in zip(snakemake.input.bulk, snakemake.input.megane):  # type: ignore\n",
    "    assert (\n",
    "        Path(m).parent.name == Path(b).parent.name\n",
    "    ), \"filenames are not sorted properly\"\n",
    "    bdf = pd.read_csv(b, sep=\"\\t\")\n",
    "    bdf.columns = bdf.columns.str.replace(\"#\", \"\")\n",
    "    bdf[\"donor_id\"] = Path(b).parent.name\n",
    "    bdata.append(bdf)\n",
    "\n",
    "    # megane\n",
    "    meg = pr.read_bed(m)\n",
    "    mdf = meg.join(\n",
    "        pr.PyRanges(bdf[[\"Chromosome\", \"Start\", \"End\", \"n_reads\", \"n_proper_pairs\"]]),\n",
    "        how=\"left\",\n",
    "    ).df\n",
    "    mdf[\"n_reads\"] = mdf[\"n_reads\"].apply(lambda x: 0 if x < 0 else x)\n",
    "    mdf[\"n_proper_pairs\"] = mdf[\"n_proper_pairs\"].apply(lambda x: 0 if x < 0 else x)\n",
    "    mdf[\"donor_id\"] = Path(m).parent.name\n",
    "    mdata.append(mdf)\n",
    "\n",
    "    # l1hs\n",
    "    ldf = l1hs.join(\n",
    "        pr.PyRanges(bdf[[\"Chromosome\", \"Start\", \"End\", \"n_reads\", \"n_proper_pairs\"]]),\n",
    "        how=\"left\",\n",
    "    ).df\n",
    "    ldf[\"n_reads\"] = ldf[\"n_reads\"].apply(lambda x: 0 if x < 0 else x)\n",
    "    ldf[\"n_proper_pairs\"] = ldf[\"n_proper_pairs\"].apply(lambda x: 0 if x < 0 else x)\n",
    "    ldf[\"donor_id\"] = Path(b).parent.name\n",
    "    ldata.append(ldf)\n",
    "\n",
    "ldata = pd.concat(ldata).merge(meta, on=\"donor_id\")\n",
    "ldata[\"locus\"] = tuple(zip(ldata[\"Chromosome\"], ldata[\"Start\"], ldata[\"End\"]))\n",
    "mdata = pd.concat(mdata).merge(meta, on=\"donor_id\")\n",
    "mdata[\"locus\"] = tuple(zip(mdata[\"Chromosome\"], mdata[\"Start\"], mdata[\"End\"]))\n",
    "bdata = pd.concat(bdata).merge(meta, on=\"donor_id\")\n",
    "bdata[\"Width\"] = bdata[\"End\"] - bdata[\"Start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprint(f\"Loaded {len(bdata)} peaks from {bdata['donor_id'].nunique()} donors\")\n",
    "avg_peaks = bdata.groupby(\"donor_id\").size().mean()\n",
    "sd_peaks = bdata.groupby(\"donor_id\").size().std()\n",
    "\n",
    "# check if sd is na, for <3-sample testing\n",
    "if not pd.isna(sd_peaks):\n",
    "    print(f\"{int(avg_peaks)} Â± {int(sd_peaks)} peaks per donor\")\n",
    "else:\n",
    "    print(f\"{int(avg_peaks)} peaks per donor\")\n",
    "\n",
    "# print all columns\n",
    "print(\"Columns:\")\n",
    "print(*bdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, axs = plt.subplots(2, 2, figsize=(16, 16), sharey=\"row\", sharex=\"col\")\n",
    "colors = sns.color_palette(\"tab10\", n_colors=2)\n",
    "\n",
    "opts = {\n",
    "    \"hue_order\": [\"CAUC\", \"AA\"],\n",
    "    \"hue\": \"race\",\n",
    "    \"palette\": {\"CAUC\": colors[0], \"AA\": colors[1]},\n",
    "    \"alpha\": 0.5,\n",
    "    \"stat\": \"count\",\n",
    "    \"log_scale\": True,\n",
    "}\n",
    "\n",
    "\n",
    "for d in bdata[\"donor_id\"].unique():\n",
    "    for ax, df in zip(\n",
    "        axs, [ldata.query(\"donor_id == @d\"), mdata.query(\"donor_id == @d\")]\n",
    "    ):\n",
    "        df = df.loc[df.groupby(\"locus\")[\"n_reads\"].idxmax()]\n",
    "        # add one for log scale\n",
    "        df[\"n_reads\"] = df[\"n_reads\"] + 1\n",
    "        df[\"n_proper_pairs\"] = df[\"n_proper_pairs\"] + 1\n",
    "        sns.ecdfplot(df, x=\"n_reads\", ax=ax[0], **opts)\n",
    "        sns.ecdfplot(df, x=\"n_proper_pairs\", ax=ax[1], **opts)\n",
    "\n",
    "axs[0, 0].set_ylabel(\"# Reference L1HS\")\n",
    "axs[1, 0].set_ylabel(\"# Non-Reference L1HS (detected from WGS)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "bdata.sort_values([\"Chromosome\", \"Start\"], inplace=True)\n",
    "df2tabix(bdata, snakemake.output[0])  # type: ignore"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
