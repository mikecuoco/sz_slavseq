{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyranges as pr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyslavseq.preprocessing import collate_labels\n",
    "\n",
    "HUE_ORDER = [\"KNRGL\", \"OTHER\", \"KRGL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(snakemake.config[\"donors\"], sep=\"\\t\", dtype={\"donor_id\": str})  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk = sorted(snakemake.input.bulk)  # type: ignore\n",
    "megane = sorted(snakemake.input.megane)  # type: ignore\n",
    "bdata, mdata = [], []\n",
    "for b, m in zip(bulk, megane):  # type: ignore\n",
    "    bdf = pd.read_parquet(b)\n",
    "    mdf = pr.read_bed(m)\n",
    "    mdf = mdf.count_overlaps(pr.PyRanges(bdf), overlap_col=\"bulk peak\").df\n",
    "    bdf[\"donor_id\"] = Path(b).parent.name\n",
    "    mdf[\"donor_id\"] = Path(b).parent.name\n",
    "    bdata.append(bdf)\n",
    "    mdata.append(mdf)\n",
    "\n",
    "bdata = pd.concat(bdata).merge(meta, on=\"donor_id\")\n",
    "print(f\"Loaded {len(bdata)} peaks from {bdata['donor_id'].nunique()} donors\")\n",
    "avg_peaks = bdata.groupby(\"donor_id\").size().mean()\n",
    "sd_peaks = bdata.groupby(\"donor_id\").size().std()\n",
    "print(f\"{int(avg_peaks)} ± {int(sd_peaks)} peaks per donor\")\n",
    "\n",
    "# label\n",
    "print(\"Labelling...\")\n",
    "bdata[\"KNRGL\"] = bdata[snakemake.params.pos_label]  # type: ignore\n",
    "bdata[\"label\"] = bdata.apply(collate_labels, axis=1)\n",
    "avg_peaks = bdata.groupby([\"label\", \"donor_id\"]).size().groupby(\"label\").mean()\n",
    "sd_peaks = bdata.groupby([\"label\", \"donor_id\"]).size().groupby(\"label\").std()\n",
    "for l in HUE_ORDER:\n",
    "    print(f\"{int(avg_peaks[l])} ± {int(sd_peaks[l])} {l} peaks per donor\")\n",
    "\n",
    "mdata = pd.concat(mdata).merge(meta, on=\"donor_id\")\n",
    "mdata[\"bulk peak\"] = mdata[\"bulk peak\"].astype(bool)\n",
    "print(f\"Loaded {len(mdata)} WGS calls from {mdata['donor_id'].nunique()} donors\")\n",
    "avg_wgs = mdata.groupby(\"donor_id\").size().mean()\n",
    "sd_wgs = mdata.groupby(\"donor_id\").size().std()\n",
    "print(f\"{int(avg_wgs)} ± {int(sd_wgs)} WGS calls per donor\")\n",
    "\n",
    "mdata = pr.PyRanges(mdata).cluster().df\n",
    "m_ndonors_call = (\n",
    "    mdata.groupby([\"Cluster\", \"bulk peak\"], observed=True)[\"donor_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"ndonors\")\n",
    ")\n",
    "m_ncalls_donor = (\n",
    "    mdata.groupby([\"donor_id\", \"bulk peak\", \"race\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"ncalls\")\n",
    "    .sort_values(\"race\")\n",
    ")\n",
    "\n",
    "bdata = pr.PyRanges(bdata).cluster().df\n",
    "b_ndonors_call = (\n",
    "    bdata.groupby([\"Cluster\", \"label\"], observed=True)[\"donor_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"ndonors\")\n",
    ")\n",
    "b_ncalls_donor = (\n",
    "    bdata.groupby([\"donor_id\", \"label\", \"race\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"ncalls\")\n",
    "    .sort_values(\"race\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee277cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO sort donors by race\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 14))\n",
    "\n",
    "sns.barplot(data=m_ncalls_donor, x=\"ncalls\", y=\"donor_id\", hue=\"bulk peak\", ax=ax1).set(\n",
    "    xlabel=\"LINE1 insertions detected from WGS\"\n",
    ")\n",
    "sns.ecdfplot(data=m_ndonors_call, x=\"ndonors\", hue=\"bulk peak\", ax=ax2).set(\n",
    "    ylabel=\"LINE1 insertions detected from WGS\", xlabel=\"# donors\"\n",
    ")\n",
    "# retitle legends\n",
    "ax1.legend_.set_title(\"Covered by Bulk SLAVseq peak\")\n",
    "ax2.legend_.set_title(\"Covered by Bulk SLAVseq peak\")\n",
    "\n",
    "\n",
    "sns.barplot(\n",
    "    data=b_ncalls_donor,\n",
    "    x=\"ncalls\",\n",
    "    y=\"donor_id\",\n",
    "    hue=\"label\",\n",
    "    hue_order=HUE_ORDER,\n",
    "    ax=ax3,\n",
    ").set(xlabel=\"Bulk SLAVseq peaks\", xscale=\"log\", xlim=(1, None))\n",
    "sns.ecdfplot(\n",
    "    data=b_ndonors_call, x=\"ndonors\", hue=\"label\", hue_order=HUE_ORDER, ax=ax4\n",
    ").set(ylabel=\"Bulk SLAVseq peaks\", xlabel=\"# donors\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first filter\n",
    "total_peaks = bdata.groupby(\"label\").size()\n",
    "bdata = bdata.query(\"max_mapq >= 30\").reset_index(drop=True)\n",
    "rm_peaks = total_peaks - bdata.groupby(\"label\").size()\n",
    "print(f\"Filtered to {len(bdata)} peaks with MAPQ >= 30\")\n",
    "for l in bdata[\"label\"].unique():\n",
    "    print(f\"Removed {rm_peaks[l]}/{total_peaks[l]} {l} peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for clonal insertions labelled \"OTHER\"\n",
    "other = bdata.query(\"label == 'OTHER'\").copy()\n",
    "other[\"Cluster\"] = other[\"Cluster\"].astype(\"category\")\n",
    "ndonors = other.groupby(\"Cluster\", observed=True)[\"donor_id\"].nunique()\n",
    "avg_reads = other.groupby(\"Cluster\", observed=True)[\"n_reads\"].mean()\n",
    "avg_n_unique_5end = other.groupby(\"Cluster\", observed=True)[\"n_unique_5end\"].mean()\n",
    "plot_df = pd.concat([ndonors, avg_reads, avg_n_unique_5end], axis=1).rename(\n",
    "    columns={\n",
    "        \"donor_id\": \"n_donors\",\n",
    "        \"n_reads\": \"avg_reads\",\n",
    "        \"n_unique_5end\": \"avg_n_unique_5end\",\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 5))\n",
    "sns.ecdfplot(data=plot_df, x=\"n_donors\", stat=\"count\", ax=ax1)\n",
    "sns.scatterplot(data=plot_df, x=\"n_donors\", y=\"avg_reads\", alpha=0.5, ax=ax2)\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.axhline(30, color=\"red\", linestyle=\"--\")\n",
    "sns.scatterplot(data=plot_df, x=\"n_donors\", y=\"avg_n_unique_5end\", alpha=0.5, ax=ax3)\n",
    "ax3.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(\n",
    "    bdata,\n",
    "    x=\"n_reads\",\n",
    "    hue=\"label\",\n",
    "    kind=\"ecdf\",\n",
    "    col=\"donor_id\",\n",
    "    col_wrap=5,\n",
    "    hue_order=HUE_ORDER,\n",
    ")\n",
    "g.set(xscale=\"log\", xlim=(1, 1e4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861f0cd",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5389c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "features = snakemake.config[\"features\"]  # type: ignore\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X = bdata[features].values\n",
    "X = scaler.fit_transform(X)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "bdata[\"PC1\"] = X[:, 0]\n",
    "bdata[\"PC2\"] = X[:, 1]\n",
    "\n",
    "bdata[\"log_n_reads\"] = np.log10(bdata[\"n_reads\"])\n",
    "bdata[\"log_rpm\"] = np.log10(bdata[\"rpm\"])\n",
    "\n",
    "hues = [\n",
    "    \"label\",\n",
    "    \"log_n_reads\",\n",
    "    \"max_mapq\",\n",
    "    \"min_mapq\",\n",
    "    \"frac_unique_3end\",\n",
    "    \"frac_unique_5end\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    1, len(hues), figsize=(5 * len(hues), 5), sharey=True, sharex=True\n",
    ")\n",
    "plt.subplots_adjust(wspace=0)\n",
    "\n",
    "for ax, hue in zip(axes, hues):\n",
    "    sns.scatterplot(data=bdata, x=\"PC1\", y=\"PC2\", hue=hue, s=3, alpha=0.7, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b99b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pca loadinsg\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "pd.DataFrame(loadings, columns=[\"PC1\", \"PC2\"], index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b41911",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdata.to_parquet(snakemake.output[0])  # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
