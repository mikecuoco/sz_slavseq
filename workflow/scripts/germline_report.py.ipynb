{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pyranges as pr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyslavseq.preprocessing import collate_labels\n",
    "\n",
    "HUE_ORDER = [\"KNRGL\", \"OTHER\", \"KRGL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b55e2d",
   "metadata": {},
   "source": [
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_flagstat(file):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "    return {\"total\": int(lines[0].split()[0]), \"duplicates\": int(lines[3].split()[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(snakemake.config[\"donors\"], sep=\"\\t\", dtype={\"donor_id\": str})  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk = sorted(snakemake.input.bulk)  # type: ignore\n",
    "flagstat = sorted(snakemake.input.flagstat)  # type: ignore\n",
    "bdata, fdata = [], []\n",
    "for b, f in zip(bulk, flagstat):  # type: ignore\n",
    "    bdf = pd.read_parquet(b)\n",
    "    bdf[\"donor_id\"] = Path(b).parent.name\n",
    "    bdata.append(bdf)\n",
    "    fdf = parse_flagstat(f)\n",
    "    fdf[\"donor_id\"] = Path(f).parent.name\n",
    "    fdata.append(fdf)\n",
    "\n",
    "bdata = pd.concat(bdata).merge(meta, on=\"donor_id\")\n",
    "fdata = pd.DataFrame(fdata)\n",
    "fdata[\"non-duplicates\"] = fdata[\"total\"] - fdata[\"duplicates\"]\n",
    "print(f\"Loaded {len(bdata)} peaks from {bdata['donor_id'].nunique()} donors\")\n",
    "avg_peaks = bdata.groupby(\"donor_id\").size().mean()\n",
    "sd_peaks = bdata.groupby(\"donor_id\").size().std()\n",
    "print(f\"{int(avg_peaks)} ± {int(sd_peaks)} peaks per donor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2914be05",
   "metadata": {},
   "source": [
    "## 2. Peak summary stats - unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f687646",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    bdata.groupby([\"libd_id\", \"race\", \"diagnosis\", \"donor_id\", \"age\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"n_peaks\")\n",
    "    .merge(fdata, on=\"donor_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"diagnosis\", \"race\", \"age\", \"total\", \"duplicates\", \"non-duplicates\"]\n",
    "g, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Define a function to calculate and annotate correlation coefficient and p-value\n",
    "def annotate_correlation(ax, data, x, y):\n",
    "    # convert y to numeric if it is a string\n",
    "    if (data[y].dtype == \"object\") or (data[y].dtype.name == \"category\"):\n",
    "        data[y] = pd.Categorical(data[y])\n",
    "        correlation_coefficient, p_value = stats.pearsonr(\n",
    "            data[x], data[y].cat.codes.astype(np.float64)\n",
    "        )\n",
    "    else:\n",
    "        correlation_coefficient, p_value = stats.pearsonr(data[x], data[y])\n",
    "    ax.text(\n",
    "        0.1,\n",
    "        0.7,\n",
    "        f\"Pearson: {correlation_coefficient:.2f}\\nP-value: {p_value:.2e}\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "\n",
    "\n",
    "for f, ax in zip(features, axs.flatten()):\n",
    "    sns.scatterplot(data=data, y=f, x=\"n_peaks\", alpha=0.5, ax=ax)\n",
    "    annotate_correlation(ax, data, \"n_peaks\", f)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_title(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scale = [\n",
    "    (\"width\", False),\n",
    "    (\"n_reads\", True),\n",
    "    (\"rpm\", True),\n",
    "    (\"n_ref_reads\", True),\n",
    "    (\"n_unique_5end\", True),\n",
    "    (\"frac_unique_5end\", False),\n",
    "    (\"n_duplicates\", True),\n",
    "    (\"frac_duplicates\", False),\n",
    "    (\"n_contigs\", True),\n",
    "    (\"frac_contigs\", False),\n",
    "    (\"min_mapq\", False),\n",
    "    (\"max_mapq\", False),\n",
    "]\n",
    "\n",
    "# subplots\n",
    "g, axs = plt.subplots(3, 4, figsize=(24, 18))\n",
    "axs = axs.flatten()\n",
    "# setup colors\n",
    "colors = sns.color_palette(\"tab10\", n_colors=2)\n",
    "opts = {\n",
    "    \"hue_order\": [\"CAUC\", \"AA\"],\n",
    "    \"hue\": \"race\",\n",
    "    \"palette\": {\"CAUC\": colors[0], \"AA\": colors[1]},\n",
    "    \"alpha\": 0.5,\n",
    "}\n",
    "\n",
    "for i, (f, s) in enumerate(features_scale):\n",
    "    for g, df in bdata.groupby(\"libd_id\"):\n",
    "        sns.ecdfplot(data=df, x=f, log_scale=s, ax=axs[i], **opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f395da",
   "metadata": {},
   "source": [
    "## 3. Peak summary stats - labelled by annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"primer_sites\",\n",
    "    \"l1hs\",\n",
    "    \"l1pa2\",\n",
    "    \"l1pa3\",\n",
    "    \"l1pa4\",\n",
    "    \"l1pa5\",\n",
    "    \"l1pa6\",\n",
    "    \"megane_gaussian\",\n",
    "    \"megane_breakpoints\",\n",
    "    \"graffite\",\n",
    "    \"xtea\",\n",
    "]\n",
    "bdata[\"other\"] = bdata[labels].sum(axis=1) == 0\n",
    "labels.append(\"other\")\n",
    "\n",
    "# plot the number of peaks per donor per label\n",
    "data = (\n",
    "    bdata.groupby([\"libd_id\", \"race\", \"diagnosis\", \"donor_id\", \"age\"])[labels]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .merge(fdata, on=\"donor_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368502db",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, axs = plt.subplots(\n",
    "    len(features),\n",
    "    len(labels),\n",
    "    figsize=(len(labels) * 6, len(features) * 6),\n",
    "    sharey=\"row\",\n",
    "    sharex=\"col\",\n",
    ")\n",
    "\n",
    "for i, f in enumerate(features):\n",
    "    for j, l in enumerate(labels):\n",
    "        sns.scatterplot(data=data, y=f, x=l, alpha=0.5, ax=axs[i, j])\n",
    "        annotate_correlation(axs[i, j], data, l, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, axs = plt.subplots(\n",
    "    len(features_scale),\n",
    "    len(labels),\n",
    "    figsize=(len(labels) * 6, len(features_scale) * 6),\n",
    ")\n",
    "\n",
    "for i, (f, s) in enumerate(features_scale):\n",
    "    for j, l in enumerate(labels):\n",
    "        for g, df in bdata.groupby(\"libd_id\"):\n",
    "            data = df[df[l]]\n",
    "            sns.ecdfplot(data=data, x=f, log_scale=s, ax=axs[i, j], **opts)\n",
    "            axs[i, j].set_title(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (f1, s1) in features_scale:\n",
    "    if f1 == \"n_reads\":\n",
    "        continue\n",
    "    print(f\"Plotting {f1}\")\n",
    "    g, axs = plt.subplots(1, 12, figsize=(72, 6))\n",
    "    for l, ax in zip(labels, axs.flatten()):\n",
    "        data = bdata[bdata[l]]\n",
    "        if s1 == True:\n",
    "            data = data[data[f1] > 0]\n",
    "        sns.histplot(data=data, x=\"n_reads\", y=f1, log_scale=(True, s1), bins=50, ax=ax)\n",
    "        ax.set_title(l)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter\n",
    "bdata = bdata.query(\"n_reads > 100 and n_duplicates > 100 and max_mapq == 60\")\n",
    "\n",
    "# label\n",
    "bdata[\"label\"] = bdata.apply(collate_labels, axis=1)\n",
    "\n",
    "# save\n",
    "bdata.to_parquet(snakemake.output[0])  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c7f57",
   "metadata": {},
   "source": [
    "## 4. Annotation stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f51df4",
   "metadata": {},
   "source": [
    "Inspect coverage of germline calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdata = pd.concat(mdata).merge(meta, on=\"donor_id\")\n",
    "# mdata[\"bulk peak\"] = mdata[\"bulk peak\"].astype(bool)\n",
    "# print(f\"Loaded {len(mdata)} WGS calls from {mdata['donor_id'].nunique()} donors\")\n",
    "# avg_wgs = mdata.groupby(\"donor_id\").size().mean()\n",
    "# sd_wgs = mdata.groupby(\"donor_id\").size().std()\n",
    "# print(f\"{int(avg_wgs)} ± {int(sd_wgs)} WGS calls per donor\")\n",
    "\n",
    "# mdata = pr.PyRanges(mdata).cluster().df\n",
    "# m_ndonors_call = (\n",
    "#     mdata.groupby([\"Cluster\", \"bulk peak\"], observed=True)[\"donor_id\"]\n",
    "#     .nunique()\n",
    "#     .reset_index(name=\"ndonors\")\n",
    "# )\n",
    "# m_ncalls_donor = (\n",
    "#     mdata.groupby([\"donor_id\", \"bulk peak\", \"race\"])\n",
    "#     .size()\n",
    "#     .reset_index(name=\"ncalls\")\n",
    "#     .sort_values(\"race\")\n",
    "# )\n",
    "\n",
    "# bdata = pr.PyRanges(bdata).cluster().df\n",
    "# b_ndonors_call = (\n",
    "#     bdata.groupby([\"Cluster\", \"label\"], observed=True)[\"donor_id\"]\n",
    "#     .nunique()\n",
    "#     .reset_index(name=\"ndonors\")\n",
    "# )\n",
    "# b_ncalls_donor = (\n",
    "#     bdata.groupby([\"donor_id\", \"label\", \"race\"])\n",
    "#     .size()\n",
    "#     .reset_index(name=\"ncalls\")\n",
    "#     .sort_values(\"race\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee277cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO sort donors by race\n",
    "# fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 14))\n",
    "\n",
    "# sns.barplot(data=m_ncalls_donor, x=\"ncalls\", y=\"donor_id\", hue=\"bulk peak\", ax=ax1).set(\n",
    "#     xlabel=\"LINE1 insertions detected from WGS\"\n",
    "# )\n",
    "# sns.ecdfplot(data=m_ndonors_call, x=\"ndonors\", hue=\"bulk peak\", ax=ax2).set(\n",
    "#     ylabel=\"LINE1 insertions detected from WGS\", xlabel=\"# donors\"\n",
    "# )\n",
    "# # retitle legends\n",
    "# ax1.legend_.set_title(\"Covered by Bulk SLAVseq peak\")\n",
    "# ax2.legend_.set_title(\"Covered by Bulk SLAVseq peak\")\n",
    "\n",
    "\n",
    "# sns.barplot(\n",
    "#     data=b_ncalls_donor,\n",
    "#     x=\"ncalls\",\n",
    "#     y=\"donor_id\",\n",
    "#     hue=\"label\",\n",
    "#     hue_order=HUE_ORDER,\n",
    "#     ax=ax3,\n",
    "# ).set(xlabel=\"Bulk SLAVseq peaks\", xscale=\"log\", xlim=(1, None))\n",
    "# sns.ecdfplot(\n",
    "#     data=b_ndonors_call, x=\"ndonors\", hue=\"label\", hue_order=HUE_ORDER, ax=ax4\n",
    "# ).set(ylabel=\"Bulk SLAVseq peaks\", xlabel=\"# donors\")\n",
    "\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look for clonal insertions labelled \"OTHER\"\n",
    "# other = bdata.query(\"label == 'OTHER'\").copy()\n",
    "# other[\"Cluster\"] = other[\"Cluster\"].astype(\"category\")\n",
    "# ndonors = other.groupby(\"Cluster\", observed=True)[\"donor_id\"].nunique()\n",
    "# avg_reads = other.groupby(\"Cluster\", observed=True)[\"n_reads\"].mean()\n",
    "# avg_n_unique_5end = other.groupby(\"Cluster\", observed=True)[\"n_unique_5end\"].mean()\n",
    "# plot_df = pd.concat([ndonors, avg_reads, avg_n_unique_5end], axis=1).rename(\n",
    "#     columns={\n",
    "#         \"donor_id\": \"n_donors\",\n",
    "#         \"n_reads\": \"avg_reads\",\n",
    "#         \"n_unique_5end\": \"avg_n_unique_5end\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 5))\n",
    "# sns.ecdfplot(data=plot_df, x=\"n_donors\", stat=\"count\", ax=ax1)\n",
    "# sns.scatterplot(data=plot_df, x=\"n_donors\", y=\"avg_reads\", alpha=0.5, ax=ax2)\n",
    "# ax2.set_yscale(\"log\")\n",
    "# ax2.axhline(30, color=\"red\", linestyle=\"--\")\n",
    "# sns.scatterplot(data=plot_df, x=\"n_donors\", y=\"avg_n_unique_5end\", alpha=0.5, ax=ax3)\n",
    "# ax3.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861f0cd",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5389c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# features = snakemake.config[\"features\"]  # type: ignore\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# pca = PCA(n_components=2)\n",
    "\n",
    "# X = bdata[features].values\n",
    "# X = scaler.fit_transform(X)\n",
    "# X = pca.fit_transform(X)\n",
    "\n",
    "# bdata[\"PC1\"] = X[:, 0]\n",
    "# bdata[\"PC2\"] = X[:, 1]\n",
    "\n",
    "# bdata[\"log_n_reads\"] = np.log10(bdata[\"n_reads\"])\n",
    "# bdata[\"log_rpm\"] = np.log10(bdata[\"rpm\"])\n",
    "\n",
    "# hues = [\n",
    "#     \"label\",\n",
    "#     \"log_n_reads\",\n",
    "#     \"max_mapq\",\n",
    "#     \"min_mapq\",\n",
    "#     \"frac_unique_3end\",\n",
    "#     \"frac_unique_5end\",\n",
    "# ]\n",
    "\n",
    "# fig, axes = plt.subplots(\n",
    "#     1, len(hues), figsize=(5 * len(hues), 5), sharey=True, sharex=True\n",
    "# )\n",
    "# plt.subplots_adjust(wspace=0)\n",
    "\n",
    "# for ax, hue in zip(axes, hues):\n",
    "#     sns.scatterplot(data=bdata, x=\"PC1\", y=\"PC2\", hue=hue, s=3, alpha=0.7, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b99b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get pca loadinsg\n",
    "# loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "# pd.DataFrame(loadings, columns=[\"PC1\", \"PC2\"], index=features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
